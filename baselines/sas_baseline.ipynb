{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b64e2acb-962e-437b-8d10-3ff85cb2f885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import ujson\n",
    "\n",
    "root_dir=\"/home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/sequential_train_test/hlen_4_bm25/\"\n",
    "\n",
    "train_sim_path = os.path.join(root_dir, \"sim_rec_sequential.train.json\")\n",
    "train_compl_path = os.path.join(root_dir, \"compl_rec_sequential.train.json\")\n",
    "test_sim_path = os.path.join(root_dir, \"sim_rec_sequential.test.json\")\n",
    "test_compl_path = os.path.join(root_dir, \"compl_rec_sequential.test.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d23f4ea-3bac-44b9-8c85-ad79b469e9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compl_rec_sequential.test.json   search_sequential.train.json\n",
      "compl_rec_sequential.train.json  sim_rec_sequential.test.json\n",
      "\u001b[0m\u001b[01;34mrec_search\u001b[0m/                      sim_rec_sequential.train.json\n",
      "search_sequential.test.json\n"
     ]
    }
   ],
   "source": [
    "ls \"/home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/sequential_train_test/hlen_4_bm25/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "839c3bef-df41-4add-9406-b7b3bc82c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(\"/home/jupyter/unity_jointly_rec_and_search/kgc-dr/\")\n",
    "\n",
    "NUM_USER=893619\n",
    "NUM_ITEM=2260878\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value.\n",
    "    Examples::\n",
    "        >>> # Initialize a meter to record loss\n",
    "        >>> losses = AverageMeter()\n",
    "        >>> # Update meter after every minibatch update\n",
    "        >>> losses.update(loss_value, batch_size)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class SASProductDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.pids = []\n",
    "        with open(path) as fin:\n",
    "            for line in fin:\n",
    "                pid, text = line.strip().split(\"\\t\")\n",
    "                self.pids.append(int(pid))\n",
    "    def __len__(self):\n",
    "        return len(self.pids)\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "        return self.pids[idx]\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        return torch.LongTensor(batch)\n",
    "\n",
    "class SASDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, path, is_train, maxlen, padding_idx=NUM_ITEM):\n",
    "        self.data = []\n",
    "        self.is_train = is_train\n",
    "        self.maxlen = maxlen\n",
    "        self.padding_idx = padding_idx\n",
    "        with open(path) as fin:\n",
    "            for line in fin:\n",
    "                self.data.append(ujson.loads(line))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.data[idx]\n",
    "        seq_len = len(example[\"context_value_ids\"])\n",
    "        assert seq_len <= self.maxlen\n",
    "        if self.is_train:\n",
    "            assert len(example[\"context_value_ids\"]) == len(example[\"target_value_ids\"]) == len(example[\"neg_value_ids\"])\n",
    "            hist_pids = [self.padding_idx] * (self.maxlen - seq_len) + example[\"context_value_ids\"]\n",
    "            target_pids = [self.padding_idx] * (self.maxlen - seq_len) + example[\"target_value_ids\"]\n",
    "            neg_pids = [self.padding_idx] * (self.maxlen - seq_len) + example[\"neg_value_ids\"]\n",
    "            assert len(hist_pids) == len(target_pids )== len(neg_pids) == self.maxlen\n",
    "        else:\n",
    "            hist_pids = [self.padding_idx] * (self.maxlen - seq_len) + example[\"context_value_ids\"]\n",
    "            assert len(hist_pids) == self.maxlen, (len(hist_pids), self.maxlen)\n",
    "        if self.is_train:\n",
    "            return (example[\"uid\"], hist_pids, target_pids, neg_pids)\n",
    "        else:\n",
    "            return (example[\"uid\"], hist_pids)\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        if self.is_train:\n",
    "            uids, hist_pids, target_pids, neg_pids = zip(*batch)\n",
    "            uids = torch.LongTensor(uids)\n",
    "            hist_pids = torch.LongTensor(hist_pids)\n",
    "            target_pids = torch.LongTensor(target_pids)\n",
    "            neg_pids = torch.LongTensor(neg_pids)\n",
    "            targets = torch.cat((torch.ones_like(target_pids, dtype=torch.float32),\n",
    "                                torch.zeros_like(neg_pids, dtype=torch.float32)), dim=-1)\n",
    "            return [\n",
    "                torch.LongTensor(uids),\n",
    "                torch.LongTensor(hist_pids),\n",
    "                torch.LongTensor(target_pids),\n",
    "                torch.LongTensor(neg_pids),\n",
    "                targets]\n",
    "        else:\n",
    "            uids, hist_pids = zip(*batch)\n",
    "            return [torch.LongTensor(uids),\n",
    "                    torch.LongTensor(hist_pids)]\n",
    "    \n",
    "\n",
    "class PointWiseFeedForward(torch.nn.Module):\n",
    "    def __init__(self, hidden_units, dropout_rate):\n",
    "\n",
    "        super(PointWiseFeedForward, self).__init__()\n",
    "\n",
    "        self.conv1 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n",
    "        self.dropout1 = torch.nn.Dropout(p=dropout_rate)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.conv2 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n",
    "        self.dropout2 = torch.nn.Dropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.dropout2(self.conv2(self.relu(self.dropout1(self.conv1(inputs.transpose(-1, -2))))))\n",
    "        outputs = outputs.transpose(-1, -2) # as Conv1D requires (N, C, Length)\n",
    "        outputs += inputs\n",
    "        return outputs\n",
    "    \n",
    "class SASRec(torch.nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(SASRec, self).__init__()\n",
    "\n",
    "        self.user_num = args.user_num\n",
    "        self.item_num = args.item_num\n",
    "        self.dev = args.device\n",
    "\n",
    "        # TODO: loss += args.l2_emb for regularizing embedding vectors during training\n",
    "        # https://stackoverflow.com/questions/42704283/adding-l1-l2-regularization-in-pytorch\n",
    "        self.item_emb = torch.nn.Embedding(self.item_num+1, args.hidden_units)\n",
    "        self.pos_emb = torch.nn.Embedding(args.maxlen, args.hidden_units) # TO IMPROVE\n",
    "        self.emb_dropout = torch.nn.Dropout(p=args.dropout_rate)\n",
    "\n",
    "        self.attention_layernorms = torch.nn.ModuleList() # to be Q for self-attention\n",
    "        self.attention_layers = torch.nn.ModuleList()\n",
    "        self.forward_layernorms = torch.nn.ModuleList()\n",
    "        self.forward_layers = torch.nn.ModuleList()\n",
    "\n",
    "        self.last_layernorm = torch.nn.LayerNorm(args.hidden_units, eps=1e-8)\n",
    "\n",
    "        for _ in range(args.num_blocks):\n",
    "            new_attn_layernorm = torch.nn.LayerNorm(args.hidden_units, eps=1e-8)\n",
    "            self.attention_layernorms.append(new_attn_layernorm)\n",
    "\n",
    "            new_attn_layer =  torch.nn.MultiheadAttention(args.hidden_units,\n",
    "                                                            args.num_heads,\n",
    "                                                            args.dropout_rate)\n",
    "            self.attention_layers.append(new_attn_layer)\n",
    "\n",
    "            new_fwd_layernorm = torch.nn.LayerNorm(args.hidden_units, eps=1e-8)\n",
    "            self.forward_layernorms.append(new_fwd_layernorm)\n",
    "\n",
    "            new_fwd_layer = PointWiseFeedForward(args.hidden_units, args.dropout_rate)\n",
    "            self.forward_layers.append(new_fwd_layer)\n",
    "\n",
    "            # self.pos_sigmoid = torch.nn.Sigmoid()\n",
    "            # self.neg_sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def log2feats(self, log_seqs):\n",
    "        seqs = self.item_emb(log_seqs)\n",
    "        seqs *= self.item_emb.embedding_dim ** 0.5\n",
    "        positions = np.tile(np.array(range(log_seqs.shape[1])), [log_seqs.shape[0], 1])\n",
    "        seqs += self.pos_emb(torch.LongTensor(positions).to(self.dev))\n",
    "        seqs = self.emb_dropout(seqs)\n",
    "\n",
    "        timeline_mask = torch.BoolTensor(log_seqs == 0).to(self.dev)\n",
    "        seqs *= ~timeline_mask.unsqueeze(-1) # broadcast in last dim\n",
    "\n",
    "        tl = seqs.shape[1] # time dim len for enforce causality\n",
    "        attention_mask = ~torch.tril(torch.ones((tl, tl), dtype=torch.bool, device=self.dev))\n",
    "\n",
    "        for i in range(len(self.attention_layers)):\n",
    "            seqs = torch.transpose(seqs, 0, 1)\n",
    "            Q = self.attention_layernorms[i](seqs)\n",
    "            mha_outputs, _ = self.attention_layers[i](Q, seqs, seqs, \n",
    "                                            attn_mask=attention_mask)\n",
    "                                            # key_padding_mask=timeline_mask\n",
    "                                            # need_weights=False) this arg do not work?\n",
    "            seqs = Q + mha_outputs\n",
    "            seqs = torch.transpose(seqs, 0, 1)\n",
    "\n",
    "            seqs = self.forward_layernorms[i](seqs)\n",
    "            seqs = self.forward_layers[i](seqs)\n",
    "            seqs *=  ~timeline_mask.unsqueeze(-1)\n",
    "\n",
    "        log_feats = self.last_layernorm(seqs) # (U, T, C) -> (U, -1, C)\n",
    "\n",
    "        return log_feats\n",
    "\n",
    "    def forward(self, user_ids, log_seqs, pos_seqs, neg_seqs): # for training        \n",
    "        log_feats = self.log2feats(log_seqs) # user_ids hasn't been used yet\n",
    "\n",
    "        pos_embs = self.item_emb(pos_seqs)\n",
    "        neg_embs = self.item_emb(neg_seqs)\n",
    "\n",
    "        pos_logits = (log_feats * pos_embs).sum(dim=-1)\n",
    "        neg_logits = (log_feats * neg_embs).sum(dim=-1)\n",
    "\n",
    "        # pos_pred = self.pos_sigmoid(pos_logits)\n",
    "        # neg_pred = self.neg_sigmoid(neg_logits)\n",
    "        \n",
    "        assert pos_logits.dim() == neg_logits.dim() == 2\n",
    "\n",
    "        return pos_logits, neg_logits # pos_pred, neg_pred\n",
    "\n",
    "    def predict(self, user_ids, log_seqs, item_indices): # for inference\n",
    "        log_feats = self.log2feats(log_seqs) # user_ids hasn't been used yet\n",
    "\n",
    "        final_feat = log_feats[:, -1, :] # only use last QKV classifier, a waste\n",
    "\n",
    "        item_embs = self.item_emb(torch.LongTensor(item_indices).to(self.dev)) # (U, I, C)\n",
    "\n",
    "        logits = item_embs.matmul(final_feat.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "        # preds = self.pos_sigmoid(logits) # rank same item list for different users\n",
    "\n",
    "        return logits # preds # (U, I)\n",
    "    \n",
    "    def query_embs(self, log_seqs):\n",
    "        return self.log2feats(log_seqs)[:, -1, :]\n",
    "    \n",
    "    def passage_embs(self, item_indices):\n",
    "        return self.item_emb(item_indices)\n",
    "    \n",
    "def train(model, train_dataloader, num_epochs=200):\n",
    "    bce_criterion = torch.nn.BCEWithLogitsLoss() # torch.nn.BCELoss()\n",
    "    adam_optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.98))\n",
    "    \n",
    "    loss_avg_meter = AverageMeter()\n",
    "    global_step = 1\n",
    "    print(\"batch: {}, step: {}, loss: {}\") \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch_idx, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n",
    "            uids, hist_pids, pos_pids, neg_pids, targets = batch\n",
    "            pos_logits, neg_logits = model(uids, hist_pids, pos_pids, neg_pids)\n",
    "            logits = torch.cat((pos_logits, neg_logits), dim=-1)\n",
    "            loss = bce_criterion(logits, targets)\n",
    "            \n",
    "            \n",
    "            loss.backward()\n",
    "            adam_optimizer.step()\n",
    "            adam_optimizer.zero_grad()\n",
    "            \n",
    "            loss_avg_meter.update(loss.item())\n",
    "        \n",
    "            if (global_step+1) % 4_000 == 0:\n",
    "                print(f\"{epoch} {global_step} {loss_avg_meter.avg:.3f}\")\n",
    "                loss_avg_meter.reset()\n",
    "            \n",
    "            global_step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6144919-2fde-4782-8fd0-c847512b6380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "batch: {}, step: {}, loss: {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:28<00:00,  3.50it/s]\n",
      "100%|██████████| 99/99 [00:40<00:00,  2.46it/s]\n",
      "100%|██████████| 99/99 [00:40<00:00,  2.42it/s]\n",
      "100%|██████████| 99/99 [00:40<00:00,  2.45it/s]\n",
      "100%|██████████| 99/99 [00:41<00:00,  2.41it/s]\n",
      "100%|██████████| 99/99 [00:37<00:00,  2.67it/s]\n",
      " 62%|██████▏   | 61/99 [00:22<00:14,  2.70it/s]"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    maxlen=5\n",
    "    hidden_units=50\n",
    "    num_blocks=2\n",
    "    num_heads=1\n",
    "    dropout_rate=0.5\n",
    "    device=\"cpu\"\n",
    "    user_num=NUM_USER\n",
    "    item_num=NUM_ITEM\n",
    "    \n",
    "args = Args\n",
    "print(args.maxlen)\n",
    "\n",
    "train_dataset = SASDataset(train_compl_path, True, args.maxlen)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,num_workers=4, shuffle=True, batch_size=128, \n",
    "                                              collate_fn=train_dataset.collate_fn)\n",
    "model = SASRec(args)\n",
    "train(model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "557d4e98-db4b-46c9-b6a4-bb85432ed88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17664/17664 [00:13<00:00, 1345.01it/s]\n",
      "encode # 79 seqs: 79it [00:00, 124.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Num 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:57<00:00, 175.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed Time: 57.1s, Elapsed Time per query: 5.7ms\n",
      "# unique query = 10000\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def get_index(model, test_dataloader, hidden_units):\n",
    "    index = faiss.IndexFlatIP(hidden_units)\n",
    "    index = faiss.IndexIDMap(index)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch_pids in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "            pid_embs = model.passage_embs(batch_pids)\n",
    "            \n",
    "            index.add_with_ids(pid_embs.numpy(), batch_pids.numpy())\n",
    "    return index \n",
    "\n",
    "def index_retrieve(index, query_embeddings, topk, batch=None):\n",
    "    print(\"Query Num\", len(query_embeddings))\n",
    "    start = timer()\n",
    "    if batch is None:\n",
    "        nn_scores, nearest_neighbors = index.search(query_embeddings, topk)\n",
    "    else:\n",
    "        query_offset_base = 0\n",
    "        pbar = tqdm(total=len(query_embeddings))\n",
    "        nearest_neighbors = []\n",
    "        nn_scores = []\n",
    "        while query_offset_base < len(query_embeddings):\n",
    "            batch_query_embeddings = query_embeddings[query_offset_base:query_offset_base+ batch]\n",
    "            batch_nn_scores, batch_nn = index.search(batch_query_embeddings, topk)\n",
    "            nearest_neighbors.extend(batch_nn.tolist())\n",
    "            nn_scores.extend(batch_nn_scores.tolist())\n",
    "            query_offset_base += len(batch_query_embeddings)\n",
    "            pbar.update(len(batch_query_embeddings))\n",
    "        pbar.close()\n",
    "\n",
    "    elapsed_time = timer() - start\n",
    "    elapsed_time_per_query = 1000 * elapsed_time / len(query_embeddings)\n",
    "    print(f\"Elapsed Time: {elapsed_time:.1f}s, Elapsed Time per query: {elapsed_time_per_query:.1f}ms\")\n",
    "    return nn_scores, nearest_neighbors\n",
    "\n",
    "def get_query_side_embeddings(model, query_dataloader):\n",
    "    embeddings = []\n",
    "    embeddings_ids = []\n",
    "    model.eval()\n",
    "    for _, batch in tqdm(enumerate(query_dataloader), disable=False, \n",
    "                                desc=f\"encode # {len(query_dataloader)} seqs\"):\n",
    "        with torch.no_grad():\n",
    "            uids, hist_pids = batch\n",
    "            reps = model.query_embs(hist_pids)\n",
    "        \n",
    "        embeddings.append(reps.numpy())\n",
    "        embeddings_ids.extend(uids.numpy())\n",
    "    \n",
    "    embeddings = np.concatenate(embeddings) \n",
    "    assert len(embeddings) == len(embeddings_ids), (len(embeddings), len(embeddings_ids))\n",
    "    \n",
    "    return embeddings, embeddings_ids\n",
    "\n",
    "\n",
    "\n",
    "data_dir = \"/home/jupyter/unity_jointly_rec_and_search/datasets/unified_user\"\n",
    "product_path = os.path.join(data_dir, \"collection_title_catalog.tsv\")\n",
    "\n",
    "product_dataset = SASProductDataset(product_path)\n",
    "product_dataloader = torch.utils.data.DataLoader(product_dataset, num_workers=4, shuffle=False, batch_size=128)\n",
    "\n",
    "#test_seq_dataset = SASDataset(test_sim_path, False, args.maxlen)\n",
    "test_seq_dataset = SASDataset(test_compl_path, False, args.maxlen)\n",
    "test_seq_dataloader = torch.utils.data.DataLoader(test_seq_dataset, num_workers=4, shuffle=False, batch_size=128,\n",
    "                                                 collate_fn=test_seq_dataset.collate_fn)\n",
    "\n",
    "index = get_index(model, product_dataloader, args.hidden_units)\n",
    "seq_embeddings, seq_ids = get_query_side_embeddings(model, test_seq_dataloader)\n",
    "nn_scores, nn_doc_ids = index_retrieve(index, seq_embeddings, 200, batch=128)\n",
    "\n",
    "qid_to_ranks = {}\n",
    "for qid, docids, scores in zip(seq_ids, nn_doc_ids, nn_scores):\n",
    "    for docid, s in zip(docids, scores):\n",
    "        if qid not in qid_to_ranks:\n",
    "            qid_to_ranks[qid] = [(docid, s)]\n",
    "        else:\n",
    "            qid_to_ranks[qid] += [(docid, s)]\n",
    "print(f\"# unique query = {len(qid_to_ranks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ae286ae9-a2fd-4ef6-9938-ca06ef61527a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MRR@10': 0.24597293650793653,\n",
       " 'QueriesWithRelevant@10': 3367,\n",
       " 'MRR@1000': 0.2500012874929283,\n",
       " 'QueriesWithRelevant@1000': 4677,\n",
       " 'Recall@50': 0.27768157869907867,\n",
       " 'Recall@1000': 0.3223696739371739,\n",
       " 'nDCG@10': 0.20138034375289013,\n",
       " 'nDCG@100': 0.2166772946713396,\n",
       " 'MAP@1000': 0.1722181902673803,\n",
       " 'QueriesRanked': 10000}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evaluation import retrieval_evaluator\n",
    "\n",
    "with open(\"./tmp_rank.run\", \"w\") as f:\n",
    "        for qid in qid_to_ranks:\n",
    "            ranks = qid_to_ranks[qid]\n",
    "            for i, (docid, s) in enumerate(ranks):\n",
    "                f.write(f\"{qid}\\t{docid}\\t{i+1}\\t{s}\\n\")\n",
    "                \n",
    "#qrels_path = os.path.join(data_dir, \"sequential_train_test/urels.sim.test.tsv\")\n",
    "qrels_path = os.path.join(data_dir, \"sequential_train_test/urels.compl.test.tsv\")\n",
    "\n",
    "evaluator = retrieval_evaluator.RankingEvaluator(qrels_path)\n",
    "evaluator.compute_metrics(\"./tmp_rank.run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "28dc99b1-4f44-4b32-bcb9-7e9f8198e607",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43425/1573166492.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqid_to_ranks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_displayhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_output_prompt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_format_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_user_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_exec_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/displayhook.py\u001b[0m in \u001b[0;36mcompute_format_data\u001b[0;34m(self, result)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \"\"\"\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;31m# This can be set to True by the write_output_prompt method in a subclass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mtype_pprinters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_printers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                 deferred_pprinters=self.deferred_printers)\n\u001b[0;32m--> 702\u001b[0;31m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m             \u001b[0mprinter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;31m# Special case for 1-item tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    553\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreakable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;31m# Special case for 1-item tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mpretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0;31m# printer registered in self.type_pprinters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_pprinters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;31m# deferred printer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_type_printers_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_pprinters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m         \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat_format\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_width\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_break_outer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/lib/pretty.py\u001b[0m in \u001b[0;36m_break_outer_groups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_break_outer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_width\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_width\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_width\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122ffb6a-31c5-4777-adb5-a72540835d47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
