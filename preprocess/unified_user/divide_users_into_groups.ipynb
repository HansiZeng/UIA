{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5d3f0-dc0c-490f-897c-8169bb373ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pickle \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SIM_RELATION = \"is_similar_to\"\n",
    "COMPL_RELATION = \"is_complementary_to\"\n",
    "REL_RELATION = \"is_relevant_to\"\n",
    "\n",
    "in_dir = \"/home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/\"\n",
    "    \n",
    "train_sim_data, train_compl_data, train_search_data = None, None, None\n",
    "data_fns = [\n",
    "    os.path.join(in_dir, \"train_sim_recs.csv\"),\n",
    "    os.path.join(in_dir, \"train_compl_recs.csv\"),\n",
    "    os.path.join(in_dir, \"train_searchs.csv\"),\n",
    "]\n",
    "datas = []\n",
    "for fn in data_fns:\n",
    "    datas.append(pd.read_csv(fn, index_col=0))\n",
    "train_sim_data, train_compl_data, train_search_data = datas\n",
    "\n",
    "\n",
    "datas = []\n",
    "test_sim_data, test_compl_data, test_search_data = None, None, None\n",
    "data_fns = [\n",
    "    os.path.join(in_dir, \"test_sim_recs.csv\"),\n",
    "    os.path.join(in_dir, \"test_compl_recs.csv\"),\n",
    "    os.path.join(in_dir, \"test_searchs.csv\"),\n",
    "]\n",
    "datas = []\n",
    "for fn in data_fns:\n",
    "    datas.append(pd.read_csv(fn, index_col=0))\n",
    "test_sim_data, test_compl_data, test_search_data = datas\n",
    "datas = None\n",
    "\n",
    "root_dir=\"/home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/\"\n",
    "eid_to_text = {}\n",
    "with open(os.path.join(root_dir, \"all_entities.tsv\")) as fin:\n",
    "    for line in fin:\n",
    "        eid, text = line.strip().split(\"\\t\")\n",
    "        eid_to_text[int(eid)] = text\n",
    "\n",
    "train_sim_data[\"relation\"] = SIM_RELATION\n",
    "test_sim_data[\"relation\"] = SIM_RELATION\n",
    "train_compl_data[\"relation\"] = COMPL_RELATION\n",
    "test_compl_data[\"relation\"] = COMPL_RELATION\n",
    "train_search_data[\"relation\"] = REL_RELATION\n",
    "test_search_data[\"relation\"] = REL_RELATION\n",
    "\n",
    "train_sim_data.rename({\"aid\": \"hid\", \"sim_pids\": \"tids\"}, axis=1, inplace=True)\n",
    "test_sim_data.rename({\"aid\": \"hid\", \"sim_pids\": \"tids\"}, axis=1, inplace=True)\n",
    "train_compl_data.rename({\"aid\": \"hid\", \"compl_pids\": \"tids\"}, axis=1, inplace=True)\n",
    "test_compl_data.rename({\"aid\": \"hid\", \"compl_pids\": \"tids\"}, axis=1, inplace=True)\n",
    "train_search_data.rename({\"qid\": \"hid\", \"rel_pids\": \"tids\"}, axis=1, inplace=True)\n",
    "test_search_data.rename({\"qid\": \"hid\", \"rel_pids\": \"tids\"}, axis=1, inplace=True)\n",
    "\n",
    "train_merge_data = pd.concat([train_sim_data, train_compl_data, train_search_data])\n",
    "train_merge_data[\"date_time\"] = pd.to_datetime(train_merge_data[\"date_time\"])\n",
    "train_merge_data = train_merge_data.sort_values(by=[\"uid\", \"date_time\"])\n",
    "\n",
    "print(\"length of sim_rec train and test = {:,}, {:,}\".format(len(train_sim_data), len(test_sim_data)))\n",
    "print(\"length of compl_rec train and test = {:,}, {:,}\".format(len(train_compl_data), len(test_compl_data)))\n",
    "print(\"length of search train and test = {:,}, {:,}\".format(len(train_search_data), len(test_search_data)))\n",
    "print(\"length of train_merge_data = {:,}\".format(len(train_merge_data)))\n",
    "print(\"number of entites = {:,}\".format(len(eid_to_text)))\n",
    "\n",
    "assert set(test_sim_data.uid).issubset(set(train_sim_data.uid)) \\\n",
    "and set(test_compl_data.uid).issubset(set(train_compl_data.uid)) \\\n",
    "and set(test_search_data.uid).issubset(set(train_search_data.uid))\n",
    "assert len(train_merge_data) == len(train_sim_data) + len(train_compl_data) + len(train_search_data)\n",
    "print(\"test users for each data are subset of their corresponding train users.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b595dd0f-5495-49d2-a34c-bcc59949d84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9. 10. 11. 14. 20. 49.] [   9    9    9 ... 1840 1955 2520]\n",
      "[ 9.  9. 10. 11. 14. 25.] [  9   9   9 ... 688 854 886]\n",
      "[ 4.  4.  4.  5.  6. 12.] [ 4  4  4 ... 41 43 50]\n"
     ]
    }
   ],
   "source": [
    "search_uids = np.array(train_search_data.uid)\n",
    "unique_search_uids, uid_counts = np.unique(search_uids, return_counts=True)\n",
    "print(np.quantile(a=uid_counts, q=[0.02, 0.2, 0.4, 0.6, 0.8, 0.975]), np.sort(uid_counts))\n",
    "\n",
    "sim_uids = np.array(train_sim_data.uid)\n",
    "unique_sim_uids, sim_uid_counts = np.unique(sim_uids, return_counts=True)\n",
    "print(np.quantile(a=sim_uid_counts, q=[0.02, 0.2, 0.4, 0.6, 0.8, 0.975]), np.sort(sim_uid_counts))\n",
    "\n",
    "compl_uids = np.array(train_compl_data.uid)\n",
    "unique_compl_uids, compl_uid_counts = np.unique(compl_uids, return_counts=True)\n",
    "print(np.quantile(a=compl_uid_counts, q=[0.02, 0.2, 0.4, 0.6, 0.8, 0.975]), np.sort(compl_uid_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8a5ad61-f84c-449e-92e3-3dd48db9a4ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1963251253.py, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_11804/1963251253.py\"\u001b[0;36m, line \u001b[0;32m25\u001b[0m\n\u001b[0;31m    for low_num, up_num itest_data_ranges:\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "search_ranges = [\n",
    "(9,10), (11,12), (13, 14), (15, 20), (21, np.max(uid_counts))]\n",
    "\n",
    "sim_ranges = [\n",
    "(9,10), (11,12), (13, 14), (15,16), (17, np.max(sim_uid_counts))]   \n",
    "\n",
    "compl_ranges = [\n",
    "(4,5), (6,7), (8,9), (10,11), (12, np.max(compl_uid_counts))]\n",
    "\n",
    "search_uid_groups, sim_uid_groups, compl_uid_groups = [], [], []\n",
    "\n",
    "# search\n",
    "for (low_num, up_num) in search_ranges:\n",
    "    mask = np.logical_and(uid_counts <= up_num, uid_counts >= low_num)\n",
    "    search_uid_groups.append(unique_search_uids[mask])\n",
    "assert np.sum(len(xs) for xs in search_uid_groups) == len(unique_search_uids)\n",
    "\n",
    "# sim_rec\n",
    "for low_num, up_num in sim_ranges:\n",
    "    mask = np.logical_and(sim_uid_counts <= up_num, sim_uid_counts >= low_num)\n",
    "    sim_uid_groups.append(unique_sim_uids[mask])\n",
    "assert np.sum(len(xs) for xs in sim_uid_groups) == len(unique_sim_uids)\n",
    "\n",
    "# compl_rec\n",
    "for low_num, up_num itest_data_ranges:\n",
    "    mask = np.logical_and(compl_uid_counts <= up_num, compl_uid_counts >= low_num)\n",
    "    compl_uid_groups.append(unique_compl_uids[mask])\n",
    "assert np.sum(len(xs) for xs in compl_uid_groups) == len(unique_compl_uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd9abdc-c344-4e99-b010-9ce8d0680822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "search_sequential: 100%|██████████| 815832/815832 [1:15:55<00:00, 179.10it/s]\n",
      "search_sequential:  29%|██▉       | 238229/815832 [13:37<35:09, 273.83it/s]  "
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import ujson \n",
    "\n",
    "\n",
    "SIM_RELATION = \"is_similar_to\"\n",
    "COMPL_RELATION = \"is_complementary_to\"\n",
    "REL_RELATION = \"is_relevant_to\"\n",
    "\n",
    "MAX_LEN=20\n",
    "out_dir = os.path.join(in_dir, \"users_divided_by_group\")\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir) \n",
    "\n",
    "seq_examples_list = []\n",
    "prefixes_to_datas= {\n",
    "    os.path.join(out_dir, \"search_sequential\"): (train_search_data, test_search_data, search_uid_groups, \"urels.search.test.tsv\"),\n",
    "    os.path.join(out_dir, \"sim_rec_sequential\"): (train_sim_data, test_sim_data, sim_uid_groups, \"urels.sim.test.tsv\"),\n",
    "    os.path.join(out_dir, \"compl_rec_sequential\"): (train_compl_data, test_compl_data, compl_uid_groups, \"urels.compl.test.tsv\"),\n",
    "}\n",
    "\n",
    "for prefix, (train_data, test_data, uid_groups, urel_path) in prefixes_to_datas.items():\n",
    "    for group_id in range(5):\n",
    "        train_seq_examples = []\n",
    "        test_seq_examples = []\n",
    "        test_uid_to_pospids = {}\n",
    "        for uid, g in tqdm(train_data.groupby(\"uid\"), desc=prefix.split(\"/\")[-1]):\n",
    "            if uid not in uid_groups[group_id]:\n",
    "                continue\n",
    "            last_time = g.iloc[-1].date_time\n",
    "            group = train_merge_data[train_merge_data.uid==uid]\n",
    "            group = group[group.date_time <= last_time]\n",
    "            \n",
    "            qids = list(group.hid)\n",
    "            group_rel_pids = list(group.tids)\n",
    "            relations = list(group.relation)\n",
    "\n",
    "            rel_pids = []\n",
    "            for xs in group_rel_pids:\n",
    "                rel_pids.append(random.sample(eval(xs), k=1)[0]) # only sample 1 relpid \n",
    "            assert len(qids) == len(rel_pids) == len(group)\n",
    "\n",
    "            uid = int(uid)\n",
    "            qids = [int(x) for x in qids]\n",
    "            rel_pids = [int(x) for x in rel_pids]\n",
    "\n",
    "            # for test\n",
    "            test_row = test_data[test_data.uid == uid]\n",
    "            if len(test_row) == 0:\n",
    "                continue\n",
    "            assert len(test_row) == 1, test_row\n",
    "\n",
    "            test_qid = int(test_row.iloc[0].hid)\n",
    "            test_relation = str(test_row.iloc[0].relation)\n",
    "\n",
    "            test_query_ids = qids[1:] + [test_qid]\n",
    "            test_context_key_ids = qids \n",
    "            test_context_value_ids = rel_pids\n",
    "            relations = relations[1:] + [test_relation]\n",
    "            assert len(test_query_ids) == len(test_context_key_ids) == len(test_context_value_ids), (len(test_query_ids), \n",
    "                                                                                    len(test_context_key_ids), len(test_context_value_ids))\n",
    "            assert len(test_query_ids) == len(relations), (len(test_query_ids), len(relations))\n",
    "\n",
    "            example = {\"uid\": uid, \"query_ids\": test_query_ids[-MAX_LEN:], \"context_key_ids\": test_context_key_ids[-MAX_LEN:], \n",
    "                       \"context_value_ids\": test_context_value_ids[-MAX_LEN:], \"relations\": relations[-MAX_LEN:]}\n",
    "            test_seq_examples.append(example)\n",
    "\n",
    "            if \"search_sequential\" in prefix:\n",
    "                test_uid_to_pospids[uid] = test_row.iloc[0].tids\n",
    "            elif \"sim_rec_sequential\" in prefix:\n",
    "                test_uid_to_pospids[uid] = test_row.iloc[0].tids\n",
    "            elif \"compl_rec_sequential\" in prefix:\n",
    "                test_uid_to_pospids[uid] = test_row.iloc[0].tids\n",
    "            else:\n",
    "                raise ValueError(f\"{prefix} not valid.\")\n",
    "\n",
    "\n",
    "        with open(prefix + f\"_group{group_id}.test.json\", \"w\") as fout:\n",
    "            for line in test_seq_examples:\n",
    "                fout.write(ujson.dumps(line) + \"\\n\")\n",
    "        with open(os.path.join(out_dir, f\"group_{group_id}_\"+urel_path), \"w\") as fout:\n",
    "            for uid, pos_pids in test_uid_to_pospids.items():\n",
    "                for pos_pid in pos_pids:\n",
    "                    fout.write(f\"{uid}\\tQ0\\t{pos_pid}\\t{1}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f602efd0-91b3-4ae5-8ce3-b09a6e09a4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 815832/815832 [00:56<00:00, 14341.34it/s]\n",
      "100%|██████████| 81664/81664 [00:05<00:00, 16295.19it/s]\n",
      "100%|██████████| 12628/12628 [00:00<00:00, 16114.30it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import ujson \n",
    "\n",
    "\n",
    "SIM_RELATION = \"is_similar_to\"\n",
    "COMPL_RELATION = \"is_complementary_to\"\n",
    "REL_RELATION = \"is_relevant_to\"\n",
    "\n",
    "MAX_LEN=20\n",
    "out_dir = os.path.join(in_dir, \"users_divided_by_group\")\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir) \n",
    "\n",
    "seq_examples_list = []\n",
    "prefixes_to_datas= {\n",
    "    os.path.join(out_dir, \"search_sequential\"): (train_search_data, test_search_data,  \"urels.search.test.tsv\"),\n",
    "    os.path.join(out_dir, \"sim_rec_sequential\"): (train_sim_data, test_sim_data,  \"urels.sim.test.tsv\"),\n",
    "    os.path.join(out_dir, \"compl_rec_sequential\"): (train_compl_data, test_compl_data,  \"urels.compl.test.tsv\"),\n",
    "}\n",
    "for prefix, (train_data, test_data, urel_path) in prefixes_to_datas.items():\n",
    "    test_uid_to_pospids = {}\n",
    "    for idx, test_row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        uid = test_row.uid\n",
    "            \n",
    "        if \"search_sequential\" in prefix:\n",
    "            test_uid_to_pospids[uid] = eval(test_row.tids)\n",
    "        elif \"sim_rec_sequential\" in prefix:\n",
    "            test_uid_to_pospids[uid] = eval(test_row.tids)\n",
    "        elif \"compl_rec_sequential\" in prefix:\n",
    "            test_uid_to_pospids[uid] = eval(test_row.tids)\n",
    "        else:\n",
    "            raise ValueError(f\"{prefix} not valid.\")\n",
    "            \n",
    "    with open(os.path.join(out_dir, urel_path), \"w\") as fout:\n",
    "        for uid, pos_pids in test_uid_to_pospids.items():\n",
    "            for pos_pid in pos_pids:\n",
    "                fout.write(f\"{uid}\\tQ0\\t{pos_pid}\\t{1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fb0d56b-b434-46ec-92b6-ac9a3e3ec51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[648908]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row.tids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae57e91-0536-4569-a3b9-47148f8ceda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b3cce-968b-40a0-8c69-d3b85bb6d179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
