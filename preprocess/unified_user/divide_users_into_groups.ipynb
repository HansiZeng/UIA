{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b52694bc-0c17-4f6f-acdb-6a8d5909cc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of sim_rec train and test = 1,017,800, 81,664\n",
      "length of compl_rec train and test = 67,310, 12,628\n",
      "length of search train and test = 13,726,249, 815,832\n",
      "number of entites = 3,214,651\n",
      "test users for each data are subset of their corresponding train users.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pickle \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "in_dir = \"/home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/\"\n",
    "    \n",
    "train_sim_data, train_compl_data, train_search_data = None, None, None\n",
    "data_fns = [\n",
    "    os.path.join(in_dir, \"train_sim_recs.csv\"),\n",
    "    os.path.join(in_dir, \"train_compl_recs.csv\"),\n",
    "    os.path.join(in_dir, \"train_searchs.csv\"),\n",
    "]\n",
    "datas = []\n",
    "for fn in data_fns:\n",
    "    datas.append(pd.read_csv(fn, index_col=0))\n",
    "train_sim_data, train_compl_data, train_search_data = datas\n",
    "\n",
    "\n",
    "datas = []\n",
    "test_sim_data, test_compl_data, test_search_data = None, None, None\n",
    "data_fns = [\n",
    "    os.path.join(in_dir, \"test_sim_recs.csv\"),\n",
    "    os.path.join(in_dir, \"test_compl_recs.csv\"),\n",
    "    os.path.join(in_dir, \"test_searchs.csv\"),\n",
    "]\n",
    "datas = []\n",
    "for fn in data_fns:\n",
    "    datas.append(pd.read_csv(fn, index_col=0))\n",
    "test_sim_data, test_compl_data, test_search_data = datas\n",
    "datas = None\n",
    "\n",
    "root_dir=\"/home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/\"\n",
    "eid_to_text = {}\n",
    "with open(os.path.join(root_dir, \"all_entities.tsv\")) as fin:\n",
    "    for line in fin:\n",
    "        eid, text = line.strip().split(\"\\t\")\n",
    "        eid_to_text[int(eid)] = text\n",
    "\n",
    "print(\"length of sim_rec train and test = {:,}, {:,}\".format(len(train_sim_data), len(test_sim_data)))\n",
    "print(\"length of compl_rec train and test = {:,}, {:,}\".format(len(train_compl_data), len(test_compl_data)))\n",
    "print(\"length of search train and test = {:,}, {:,}\".format(len(train_search_data), len(test_search_data)))\n",
    "print(\"number of entites = {:,}\".format(len(eid_to_text)))\n",
    "\n",
    "assert set(test_sim_data.uid).issubset(set(train_sim_data.uid)) \\\n",
    "and set(test_compl_data.uid).issubset(set(train_compl_data.uid)) \\\n",
    "and set(test_search_data.uid).issubset(set(train_search_data.uid))\n",
    "print(\"test users for each data are subset of their corresponding train users.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b595dd0f-5495-49d2-a34c-bcc59949d84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9. 10. 13. 18. 28.] [   9    9    9 ... 1840 1955 2520]\n",
      "[ 9.  9. 11. 13. 17.] [  9   9   9 ... 688 854 886]\n",
      "[4. 4. 4. 6. 8.] [ 4  4  4 ... 41 43 50]\n"
     ]
    }
   ],
   "source": [
    "search_uids = np.array(train_search_data.uid)\n",
    "unique_search_uids, uid_counts = np.unique(search_uids, return_counts=True)\n",
    "print(np.quantile(a=uid_counts, q=[0.1, 0.25, 0.5, 0.75, 0.9]), np.sort(uid_counts))\n",
    "\n",
    "sim_uids = np.array(train_sim_data.uid)\n",
    "unique_sim_uids, sim_uid_counts = np.unique(sim_uids, return_counts=True)\n",
    "print(np.quantile(a=sim_uid_counts, q=[0.1, 0.25, 0.5, 0.75, 0.9]), np.sort(sim_uid_counts))\n",
    "\n",
    "compl_uids = np.array(train_compl_data.uid)\n",
    "unique_compl_uids, compl_uid_counts = np.unique(compl_uids, return_counts=True)\n",
    "print(np.quantile(a=compl_uid_counts, q=[0.1, 0.25, 0.5, 0.75, 0.9]), np.sort(compl_uid_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8a5ad61-f84c-449e-92e3-3dd48db9a4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:28: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n"
     ]
    }
   ],
   "source": [
    "search_ranges = [\n",
    "(9,12), (13,16), (17,20), (21, 24), (25, np.max(uid_counts))]\n",
    "\n",
    "sim_ranges = [\n",
    "(9,11), (12,14), (15, 17), (18,20), (21, np.max(sim_uid_counts))]   \n",
    "\n",
    "compl_ranges = [\n",
    "(4,6), (7,9), (10,12), (13,15), (16, np.max(compl_uid_counts))]\n",
    "\n",
    "search_uid_groups, sim_uid_groups, compl_uid_groups = [], [], []\n",
    "\n",
    "# search\n",
    "for low_num, up_num in search_ranges:\n",
    "    mask = np.logical_and(uid_counts <= up_num, uid_counts >= low_num)\n",
    "    search_uid_groups.append(unique_search_uids[mask])\n",
    "assert np.sum(len(xs) for xs in search_uid_groups) == len(unique_search_uids)\n",
    "\n",
    "# sim_rec\n",
    "for low_num, up_num in sim_ranges:\n",
    "    mask = np.logical_and(sim_uid_counts <= up_num, sim_uid_counts >= low_num)\n",
    "    sim_uid_groups.append(unique_sim_uids[mask])\n",
    "assert np.sum(len(xs) for xs in sim_uid_groups) == len(unique_sim_uids)\n",
    "\n",
    "# compl_rec\n",
    "for low_num, up_num in compl_ranges:\n",
    "    mask = np.logical_and(compl_uid_counts <= up_num, compl_uid_counts >= low_num)\n",
    "    compl_uid_groups.append(unique_compl_uids[mask])\n",
    "assert np.sum(len(xs) for xs in compl_uid_groups) == len(unique_compl_uids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3fd9abdc-c344-4e99-b010-9ce8d0680822",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "search_sequential: 100%|██████████| 815832/815832 [13:21<00:00, 1017.75it/s]\n",
      "search_sequential: 100%|██████████| 815832/815832 [05:56<00:00, 2290.86it/s]\n",
      "search_sequential: 100%|██████████| 815832/815832 [03:09<00:00, 4313.65it/s]\n",
      "search_sequential: 100%|██████████| 815832/815832 [01:52<00:00, 7282.66it/s]\n",
      "search_sequential: 100%|██████████| 815832/815832 [04:08<00:00, 3281.12it/s]\n",
      "sim_rec_sequential: 100%|██████████| 81664/81664 [00:53<00:00, 1532.86it/s]\n",
      "sim_rec_sequential: 100%|██████████| 81664/81664 [00:19<00:00, 4214.93it/s]\n",
      "sim_rec_sequential: 100%|██████████| 81664/81664 [00:09<00:00, 8994.76it/s] \n",
      "sim_rec_sequential: 100%|██████████| 81664/81664 [00:04<00:00, 17315.24it/s]\n",
      "sim_rec_sequential: 100%|██████████| 81664/81664 [00:06<00:00, 12006.40it/s]\n",
      "compl_rec_sequential: 100%|██████████| 12628/12628 [00:09<00:00, 1346.19it/s]\n",
      "compl_rec_sequential: 100%|██████████| 12628/12628 [00:01<00:00, 8334.72it/s]\n",
      "compl_rec_sequential: 100%|██████████| 12628/12628 [00:00<00:00, 24522.02it/s]\n",
      "compl_rec_sequential: 100%|██████████| 12628/12628 [00:00<00:00, 42425.21it/s]\n",
      "compl_rec_sequential: 100%|██████████| 12628/12628 [00:00<00:00, 40372.36it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "import ujson \n",
    "\n",
    "\n",
    "SIM_RELATION = \"is_similar_to\"\n",
    "COMPL_RELATION = \"is_complementary_to\"\n",
    "REL_RELATION = \"is_relevant_to\"\n",
    "\n",
    "MAX_LEN=10\n",
    "out_dir = os.path.join(in_dir, \"users_divided_by_group\")\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir) \n",
    "\n",
    "seq_examples_list = []\n",
    "prefixes_to_datas= {\n",
    "    os.path.join(out_dir, \"search_sequential\"): (train_search_data, test_search_data, search_uid_groups, \"urels.search.test.tsv\"),\n",
    "    os.path.join(out_dir, \"sim_rec_sequential\"): (train_sim_data, test_sim_data, sim_uid_groups, \"urels.sim.test.tsv\"),\n",
    "    os.path.join(out_dir, \"compl_rec_sequential\"): (train_compl_data, test_compl_data, compl_uid_groups, \"urels.compl.test.tsv\"),\n",
    "}\n",
    "\n",
    "for prefix, (train_data, test_data, uid_groups, urel_path) in prefixes_to_datas.items():\n",
    "    for group_id in range(5):\n",
    "        train_seq_examples = []\n",
    "        test_seq_examples = []\n",
    "        test_uid_to_pospids = {}\n",
    "        for uid, group in tqdm(train_data.groupby(\"uid\"), desc=prefix.split(\"/\")[-1]):\n",
    "            if uid not in uid_groups[group_id]:\n",
    "                continue\n",
    "            if \"search_sequential\" in prefix:\n",
    "                qids = list(group.qid)\n",
    "                group_rel_pids = group.rel_pids \n",
    "            elif \"sim_rec_sequential\" in prefix:\n",
    "                qids = list(group.aid)\n",
    "                group_rel_pids = group.sim_pids\n",
    "            elif \"compl_rec_sequential\" in prefix:\n",
    "                qids = list(group.aid)\n",
    "                group_rel_pids = group.compl_pids\n",
    "            else:\n",
    "                raise ValueError(f\"{prefix} not valid.\")\n",
    "\n",
    "            rel_pids = []\n",
    "            for xs in group_rel_pids:\n",
    "                rel_pids.append(random.sample(eval(xs), k=1)[0]) # only sample 1 relpid \n",
    "            assert len(qids) == len(rel_pids) == len(group)\n",
    "\n",
    "            uid = int(uid)\n",
    "            qids = [int(x) for x in qids]\n",
    "            rel_pids = [int(x) for x in rel_pids]\n",
    "\n",
    "            query_ids = qids[1:]\n",
    "            context_key_ids = qids[:-1]\n",
    "            context_value_ids = rel_pids[:-1]\n",
    "            target_value_ids = rel_pids[1:]\n",
    "            assert len(query_ids) == len(context_key_ids) == len(context_value_ids) == len(target_value_ids)\n",
    "\n",
    "            # for test\n",
    "            test_row = test_data[test_data.uid == uid]\n",
    "            assert len(test_row) != 0\n",
    "            assert len(test_row) == 1, test_row\n",
    "\n",
    "            if \"search_sequential\" in prefix:\n",
    "                test_qid = int(test_row.iloc[0].qid)\n",
    "                relations = len(qids) * [REL_RELATION]\n",
    "            elif \"sim_rec_sequential\" in prefix:\n",
    "                test_qid = int(test_row.iloc[0].aid)\n",
    "                relations = len(qids) * [SIM_RELATION]\n",
    "            elif \"compl_rec_sequential\" in prefix:\n",
    "                test_qid = int(test_row.iloc[0].aid)\n",
    "                relations = len(qids) * [COMPL_RELATION]\n",
    "            else:\n",
    "                raise ValueError(f\"{prefix} not valid.\") \n",
    "\n",
    "            test_query_ids = qids[1:] + [test_qid]\n",
    "            test_context_key_ids = qids \n",
    "            test_context_value_ids = rel_pids\n",
    "            assert len(test_query_ids) == len(test_context_key_ids) == len(test_context_value_ids), (len(test_query_ids), \n",
    "                                                                                    len(test_context_key_ids), len(test_context_value_ids))\n",
    "            assert len(relations) == len(test_query_ids)\n",
    "\n",
    "            example = {\"uid\": uid, \"query_ids\": test_query_ids[:MAX_LEN], \"context_key_ids\": test_context_key_ids[:MAX_LEN], \n",
    "                       \"context_value_ids\": test_context_value_ids[:MAX_LEN], \"relations\": relations[:MAX_LEN]}\n",
    "            test_seq_examples.append(example)\n",
    "\n",
    "            if \"search_sequential\" in prefix:\n",
    "                test_uid_to_pospids[uid] = eval(test_row.iloc[0].rel_pids)\n",
    "            elif \"sim_rec_sequential\" in prefix:\n",
    "                test_uid_to_pospids[uid] = eval(test_row.iloc[0].sim_pids)\n",
    "            elif \"compl_rec_sequential\" in prefix:\n",
    "                test_uid_to_pospids[uid] = eval(test_row.iloc[0].compl_pids)\n",
    "            else:\n",
    "                raise ValueError(f\"{prefix} not valid.\")\n",
    "\n",
    "\n",
    "        with open(prefix + f\"_group{group_id}.test.json\", \"w\") as fout:\n",
    "            for line in test_seq_examples:\n",
    "                fout.write(ujson.dumps(line) + \"\\n\")\n",
    "        with open(os.path.join(out_dir, f\"group_{group_id}_\"+urel_path), \"w\") as fout:\n",
    "            for uid, pos_pids in test_uid_to_pospids.items():\n",
    "                for pos_pid in pos_pids:\n",
    "                    fout.write(f\"{uid}\\tQ0\\t{pos_pid}\\t{1}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f602efd0-91b3-4ae5-8ce3-b09a6e09a4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[536313, 36596]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(test_row.iloc[0].rel_pids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6fb0d56b-b434-46ec-92b6-ac9a3e3ec51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compl_rec_sequential_group0.test.json  group_3_urels.search.test.tsv\n",
      "compl_rec_sequential_group1.test.json  group_3_urels.sim.test.tsv\n",
      "compl_rec_sequential_group2.test.json  group_4_urels.compl.test.tsv\n",
      "compl_rec_sequential_group3.test.json  group_4_urels.search.test.tsv\n",
      "compl_rec_sequential_group4.test.json  group_4_urels.sim.test.tsv\n",
      "group_0_urels.compl.test.tsv\t       search_sequential_group0.test.json\n",
      "group_0_urels.search.test.tsv\t       search_sequential_group1.test.json\n",
      "group_0_urels.sim.test.tsv\t       search_sequential_group2.test.json\n",
      "group_1_urels.compl.test.tsv\t       search_sequential_group3.test.json\n",
      "group_1_urels.search.test.tsv\t       search_sequential_group4.test.json\n",
      "group_1_urels.sim.test.tsv\t       sim_rec_sequential_group0.test.json\n",
      "group_2_urels.compl.test.tsv\t       sim_rec_sequential_group1.test.json\n",
      "group_2_urels.search.test.tsv\t       sim_rec_sequential_group2.test.json\n",
      "group_2_urels.sim.test.tsv\t       sim_rec_sequential_group3.test.json\n",
      "group_3_urels.compl.test.tsv\t       sim_rec_sequential_group4.test.json\n"
     ]
    }
   ],
   "source": [
    "! ls $out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cae57e91-0536-4569-a3b9-47148f8ceda2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/users_divided_by_group'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b3cce-968b-40a0-8c69-d3b85bb6d179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
