{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15463916-0e97-4151-bbda-6a7d979f1ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "\n",
    "in_dir = \"/home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/\"\n",
    "\n",
    "datas = []\n",
    "fns = [\n",
    "    os.path.join(in_dir, \"train_sim_recs.csv\"),\n",
    "    os.path.join(in_dir, \"test_sim_recs.csv\"),\n",
    "    os.path.join(in_dir, \"train_compl_recs.csv\"),\n",
    "    os.path.join(in_dir, \"test_compl_recs.csv\"),\n",
    "    os.path.join(in_dir, \"train_searchs.csv\"),\n",
    "    os.path.join(in_dir, \"test_searchs.csv\"),\n",
    "]\n",
    "\n",
    "for fn in fns:\n",
    "    datas.append(pd.read_csv(fn, index_col=0))\n",
    "    \n",
    "train_sim_data, test_sim_data, train_compl_data, test_compl_data, train_search_data, test_search_data = datas\n",
    "sim_data = pd.concat([train_sim_data, test_sim_data])\n",
    "compl_data = pd.concat([train_compl_data, test_compl_data])\n",
    "search_data = pd.concat([train_search_data, test_search_data])\n",
    "assert len(sim_data) == len(train_sim_data) + len(test_sim_data) \n",
    "assert len(compl_data) == len(train_compl_data) + len(test_compl_data) \n",
    "assert len(search_data) == len(train_search_data) + len(test_search_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "50625952-79d4-4a39-b5c2-95a6428c77d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of selected sim, compl, search users 8,166, 1,262, 10,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 330924/330924 [00:01<00:00, 177863.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sim_arels, compl_arels, search_qrels = 321,960, 58,493, 2,463,484\n",
      "test sim_arels, compl_arels, search_qrels = 71,517, 10,521, 203,891\n",
      "after difference, test sim_arels, compl_arels, search_qrels = 24,429, 5,246, 19,858\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "import pickle as pkl\n",
    "import pandas as pd\n",
    "random.seed(4680)\n",
    "\n",
    "out_dir = os.path.join(in_dir, \"zero_shot\")\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "max_user_num = 10_000\n",
    "selected_sim_users = random.sample(list(sim_data.uid), k=min(max_user_num, int(len(sim_data.uid.unique())*0.1)))\n",
    "selected_compl_users = random.sample(list(compl_data.uid), k=min(max_user_num, int(len(compl_data.uid.unique())*0.1)))\n",
    "selected_search_users = random.sample(list(search_data.uid), k=min(max_user_num, int(len(search_data.uid.unique())*0.1)))\n",
    "\n",
    "print(\"number of selected sim, compl, search users {:,}, {:,}, {:,}\".format(len(selected_sim_users), len(selected_compl_users), \n",
    "                                                                            len(selected_search_users)))\n",
    "\n",
    "test_sim_data = sim_data[np.in1d(sim_data.uid, selected_sim_users)]\n",
    "test_compl_data = compl_data[np.in1d(compl_data.uid, selected_compl_users)]\n",
    "test_search_data = search_data[np.in1d(search_data.uid, selected_search_users)]\n",
    "\n",
    "train_sim_data = sim_data[~np.in1d(sim_data.uid, selected_sim_users)]\n",
    "train_compl_data = compl_data[~np.in1d(compl_data.uid, selected_compl_users)]\n",
    "train_search_data = search_data[~np.in1d(search_data.uid, selected_search_users)]\n",
    "\n",
    "assert len(test_sim_data) + len(train_sim_data) == len(sim_data) and len(test_compl_data) + len(train_compl_data) == len(compl_data)\n",
    "assert len(test_search_data) + len(train_search_data) == len(search_data)\n",
    "\n",
    "train_aid_to_simpids, train_aid_to_complpids, train_qid_to_pids = defaultdict(set), defaultdict(set), defaultdict(set)\n",
    "test_aid_to_simpids, test_aid_to_complpids, test_qid_to_pids = defaultdict(set), defaultdict(set), defaultdict(set)\n",
    "for aid, simpids in zip(train_sim_data.aid, train_sim_data.sim_pids):\n",
    "    train_aid_to_simpids[aid].update(eval(simpids))\n",
    "for aid, simpids in zip(test_sim_data.aid, test_sim_data.sim_pids):\n",
    "    test_aid_to_simpids[aid].update(eval(simpids))\n",
    "for aid, complpids in zip(train_compl_data.aid, train_compl_data.compl_pids):\n",
    "    train_aid_to_complpids[aid].update(eval(complpids))\n",
    "for aid, complpids in zip(test_compl_data.aid, test_compl_data.compl_pids):\n",
    "    test_aid_to_complpids[aid].update(eval(complpids))\n",
    "for qid, relpids in zip(train_search_data.qid, train_search_data.rel_pids):\n",
    "    train_qid_to_pids[qid].update(eval(relpids))\n",
    "for qid, relpids in tqdm(zip(test_search_data.qid, test_search_data.rel_pids), total=len(test_search_data)):\n",
    "    test_qid_to_pids[qid].update(eval(relpids))\n",
    "    \n",
    "\n",
    "print(\"train sim_arels, compl_arels, search_qrels = {:,}, {:,}, {:,}\".format(\n",
    "    sum([len(x) for x in train_aid_to_simpids.values()]), sum([len(x) for x in train_aid_to_complpids.values()]), \n",
    "    sum([len(x) for x in train_qid_to_pids.values()])\n",
    "))\n",
    "print(\"test sim_arels, compl_arels, search_qrels = {:,}, {:,}, {:,}\".format(\n",
    "    sum([len(x) for x in test_aid_to_simpids.values()]), sum([len(x) for x in test_aid_to_complpids.values()]), \n",
    "    sum([len(x) for x in test_qid_to_pids.values()])\n",
    "))\n",
    "\n",
    "exclude_aid_to_simpids, exclude_aid_to_complpids, exclude_qid_to_pids = {}, {}, {}\n",
    "for aid, simpids in test_aid_to_simpids.items():\n",
    "    if aid in train_aid_to_simpids:\n",
    "        exclude_pids = simpids.difference(train_aid_to_simpids[aid])\n",
    "    else:\n",
    "        exclude_pids = simpids\n",
    "    exclude_aid_to_simpids[aid] = exclude_pids\n",
    "for aid, complpids in test_aid_to_complpids.items():\n",
    "    if aid in train_aid_to_complpids:\n",
    "        exclude_pids = complpids.difference(train_aid_to_complpids[aid])\n",
    "    else:\n",
    "        exclude_pids = complpids\n",
    "    exclude_aid_to_complpids[aid] = exclude_pids\n",
    "for qid, pids in test_qid_to_pids.items():\n",
    "    if qid in train_qid_to_pids:\n",
    "        exclude_pids = pids.difference(train_qid_to_pids[qid])\n",
    "    else:\n",
    "        exclude_pids = pids\n",
    "    exclude_qid_to_pids[qid] = exclude_pids\n",
    "    \n",
    "print(\"after difference, test sim_arels, compl_arels, search_qrels = {:,}, {:,}, {:,}\".format(\n",
    "    sum([len(x) for x in exclude_aid_to_simpids.values()]), sum([len(x) for x in exclude_aid_to_complpids.values()]), \n",
    "    sum([len(x) for x in exclude_qid_to_pids.values()])\n",
    "))\n",
    "\n",
    "fn_to_data = {\n",
    "    os.path.join(out_dir, \"exclude_aid_to_simpids.pkl\"): exclude_aid_to_simpids,\n",
    "    os.path.join(out_dir, \"exclude_aid_to_complpids.pkl\"): exclude_aid_to_complpids,\n",
    "    os.path.join(out_dir, \"exclude_qid_to_relpids.pkl\"): exclude_qid_to_pids,\n",
    "}\n",
    "for fn, data in fn_to_data.items():\n",
    "    with open(fn, \"wb\") as fout:\n",
    "        pkl.dump(data, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90550997-bd47-417c-bc12-0db3b47310b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ignore hids = 6644\n"
     ]
    }
   ],
   "source": [
    "def create_neg_value_ids(query_ids, pos_value_ids, miss_qids, sampler=None):\n",
    "    assert type(sampler) == dict\n",
    "    assert len(query_ids) == len(pos_value_ids)\n",
    "    neg_value_ids = []\n",
    "    for qid, pos_vid in zip(query_ids, pos_value_ids):\n",
    "        if qid not in sampler:\n",
    "            miss_qids.add(qid)\n",
    "            neg_vid = random.sample(range(2_000_000), k=1)[0]\n",
    "            while neg_vid == pos_vid:\n",
    "                neg_vid = random.sample(range(2_000_000), k=1)[0]\n",
    "            neg_value_ids.append(neg_vid)\n",
    "        else:\n",
    "            neg_vid = random.sample(sampler[qid], k=1)[0]\n",
    "            while neg_vid == pos_vid:\n",
    "                neg_vid = random.sample(range(2_000_000), k=1)[0]\n",
    "            neg_value_ids.append(neg_vid)\n",
    "    \n",
    "    assert len(neg_value_ids) == len(pos_value_ids)\n",
    "    \n",
    "    return neg_value_ids\n",
    "\n",
    "run_path = os.path.join(in_dir, \"runs/bm25.all.run\")\n",
    "df = pd.read_csv(run_path, sep=\" \", names=[\"hid\", \"q0\", \"tid\", \"rank\", \"score\", \"model_name\"])\n",
    "bm25_hid_to_tids = {}\n",
    "ignore_hids = set()\n",
    "for hid, group in df.groupby(\"hid\"):\n",
    "    cand_tids = list(group.tid.values)\n",
    "    if len(cand_tids) < 10:\n",
    "        ignore_hids.add(int(hid))\n",
    "    else:\n",
    "        bm25_hid_to_tids[int(hid)] = [int(x) for x in cand_tids]\n",
    "        \n",
    "print(\"number of ignore hids = {}\".format(len(ignore_hids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c6c02c37-284f-4317-a274-0ab434830e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 805946/805946 [05:38<00:00, 2381.33it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_hids for search_sequential: 45,210.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9886/9886 [00:06<00:00, 1577.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_hids for search_sequential: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74036/74036 [00:22<00:00, 3358.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_hids for sim_rec_sequential: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7628/7628 [00:03<00:00, 2487.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_hids for sim_rec_sequential: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11424/11424 [00:02<00:00, 4267.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_hids for compl_rec_sequential: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1204/1204 [00:00<00:00, 3693.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_hids for compl_rec_sequential: 0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_sequential_examples(data, prefix, bm25_hid_to_tids, is_train=True):\n",
    "    seq_examples = []\n",
    "    miss_hids = set()\n",
    "    for uid, group in tqdm(data.groupby(\"uid\")):\n",
    "        if \"search_sequential\" in prefix:\n",
    "            qids = list(group.qid)\n",
    "            group_rel_pids = group.rel_pids \n",
    "        elif \"sim_rec_sequential\" in prefix:\n",
    "            qids = list(group.aid)\n",
    "            group_rel_pids = group.sim_pids\n",
    "        elif \"compl_rec_sequential\" in prefix:\n",
    "            qids = list(group.aid)\n",
    "            group_rel_pids = group.compl_pids\n",
    "        else:\n",
    "            raise ValueError(f\"{prefix} not valid.\")\n",
    "            \n",
    "        rel_pids = []\n",
    "        for xs in group_rel_pids:\n",
    "            rel_pids.append(random.sample(eval(xs), k=1)[0]) # only sample 1 relpid \n",
    "        assert len(qids) == len(rel_pids) == len(group)\n",
    "        \n",
    "        if is_train:\n",
    "            target_value_ids = [int(x) for x in rel_pids[1:]]\n",
    "        else:\n",
    "            target_value_ids = [eval(xs) for xs in group_rel_pids][1:]\n",
    "            target_value_ids = [[int(x) for x in xs] for xs in target_value_ids]\n",
    "\n",
    "        uid = int(uid)\n",
    "        qids = [int(x) for x in qids]\n",
    "        rel_pids = [int(x) for x in rel_pids]\n",
    "\n",
    "        query_ids = qids[1:]\n",
    "        context_key_ids = qids[:-1]\n",
    "        context_value_ids = rel_pids[:-1]\n",
    "            \n",
    "        assert len(query_ids) == len(context_key_ids) == len(context_value_ids) == len(target_value_ids)\n",
    "        \n",
    "        if is_train:\n",
    "            if \"sim_rec_sequential\" in prefix:\n",
    "                neg_value_ids = random.sample(range(2_000_000), k=len(target_value_ids))\n",
    "            elif \"search_sequential\" in prefix or \"compl_rec_sequential\" in prefix:\n",
    "                neg_value_ids = create_neg_value_ids(query_ids=query_ids, \n",
    "                                                     pos_value_ids=target_value_ids, \n",
    "                                                     miss_qids=miss_hids, \n",
    "                                                     sampler=bm25_hid_to_tids)\n",
    "            else:\n",
    "                raise ValueError(f\"prefix: {prefix} is not valid.\")\n",
    "            example = {\"uid\": uid, \"query_ids\": query_ids, \"context_key_ids\": context_key_ids, \"context_value_ids\": context_value_ids,\n",
    "                        \"target_value_ids\": target_value_ids, \"neg_value_ids\": neg_value_ids}\n",
    "        else:\n",
    "            example = {\"uid\": uid, \"query_ids\": query_ids, \"context_key_ids\": context_key_ids, \"context_value_ids\": context_value_ids,\n",
    "                        \"target_value_ids\": target_value_ids}\n",
    "        \n",
    "        seq_examples.append(example)\n",
    "    print(f\"miss_hids for {prefix}: {len(miss_hids):,}.\")\n",
    "        \n",
    "    return seq_examples\n",
    "\n",
    "train_search_examples = get_sequential_examples(train_search_data, \"search_sequential\", bm25_hid_to_tids, is_train=True)\n",
    "test_search_examples = get_sequential_examples(test_search_data, \"search_sequential\", bm25_hid_to_tids, is_train=False)\n",
    "train_sim_examples = get_sequential_examples(train_sim_data, \"sim_rec_sequential\", bm25_hid_to_tids, is_train=True)\n",
    "test_sim_examples = get_sequential_examples(test_sim_data, \"sim_rec_sequential\", bm25_hid_to_tids, is_train=False)\n",
    "train_compl_examples = get_sequential_examples(train_compl_data, \"compl_rec_sequential\", bm25_hid_to_tids, is_train=True)\n",
    "test_compl_examples = get_sequential_examples(test_compl_data, \"compl_rec_sequential\", bm25_hid_to_tids, is_train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "df904b57-3ac7-4f96-bed6-f94824ea8945",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9886/9886 [00:00<00:00, 96231.02it/s]\n",
      "100%|██████████| 7628/7628 [00:00<00:00, 115473.59it/s]\n",
      "100%|██████████| 1204/1204 [00:00<00:00, 124742.29it/s]\n",
      "100%|██████████| 805946/805946 [00:24<00:00, 33062.43it/s] \n",
      "100%|██████████| 74036/74036 [00:00<00:00, 313172.04it/s]\n",
      "100%|██████████| 11424/11424 [00:00<00:00, 261217.94it/s]\n"
     ]
    }
   ],
   "source": [
    "import ujson\n",
    "\n",
    "hlen = 4\n",
    "dest_dir = os.path.join(out_dir, f\"sequential_train_test_hlen_{hlen}_bm25\")\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.mkdir(dest_dir)\n",
    "    \n",
    "SIM_RELATION = \"is_similar_to\"\n",
    "COMPL_RELATION = \"is_complementary_to\"\n",
    "REL_RELATION = \"is_relevant_to\"\n",
    "    \n",
    "prefix_to_data = {\n",
    "    \"search_sequential\": (test_search_examples, REL_RELATION),\n",
    "    \"sim_rec_sequential\": (test_sim_examples, SIM_RELATION),\n",
    "    \"compl_rec_sequential\": (test_compl_examples, COMPL_RELATION)\n",
    "}\n",
    "for prefix, (test_examples, relation) in prefix_to_data.items():\n",
    "    num_j = 3\n",
    "    test_id = 0\n",
    "    out_examples = []\n",
    "    tid_to_pospids = {}\n",
    "    for example in tqdm(test_examples, total=len(test_examples)):\n",
    "        max_len = len(example[\"query_ids\"])\n",
    "        for j in range(num_j):\n",
    "            end_idx = max_len - j\n",
    "            start_idx = max(0, max_len - j - hlen)\n",
    "            assert end_idx > 0 and end_idx > start_idx\n",
    "\n",
    "            out_example = {\"uid\": example[\"uid\"], 'query_ids': example['query_ids'][start_idx:end_idx], \n",
    "                           'context_key_ids': example['context_key_ids'][start_idx:end_idx], \n",
    "                           'context_value_ids': example['context_value_ids'][start_idx:end_idx], \"relation\": relation,\n",
    "                          \"test_id\": test_id}\n",
    "            out_examples.append(out_example)\n",
    "            tid_to_pospids[test_id] = example[\"target_value_ids\"][end_idx-1]\n",
    "            test_id += 1\n",
    "            \n",
    "    with open(os.path.join(dest_dir, f\"{prefix}.test.json\"), \"w\") as fout:\n",
    "        for example in out_examples:\n",
    "            fout.write(ujson.dumps(example) + \"\\n\")\n",
    "    with open(os.path.join(dest_dir, f\"{prefix}.trels.tsv\"), \"w\") as fout:\n",
    "        for tid, pospid in tid_to_pospids.items():\n",
    "            for pospid in pospid:\n",
    "                fout.write(f\"{tid}\\tQ0\\t{pospid}\\t{1}\\n\")\n",
    "    \n",
    "    \n",
    "fn_to_data = {\n",
    "    os.path.join(dest_dir, \"search_sequential.train.json\"): (train_search_examples, REL_RELATION),\n",
    "    os.path.join(dest_dir, \"sim_rec_sequential.train.json\"): (train_sim_examples, SIM_RELATION),\n",
    "    os.path.join(dest_dir, \"compl_rec_sequential.train.json\"): (train_compl_examples, COMPL_RELATION)\n",
    "}\n",
    "for fn, (train_examples,relation) in fn_to_data.items():\n",
    "    out_examples = []\n",
    "    for example in tqdm(train_examples, total=len(train_examples)):\n",
    "        max_len = len(example[\"query_ids\"])\n",
    "        start_idx = max(0, max_len-hlen)\n",
    "        \n",
    "        out_example = {\"uid\": example[\"uid\"], 'query_ids': example['query_ids'][start_idx:], \n",
    "                           'context_key_ids': example['context_key_ids'][start_idx:], \n",
    "                           'context_value_ids': example['context_value_ids'][start_idx:],\n",
    "                            'target_value_ids': example['target_value_ids'][start_idx:],\n",
    "                              'neg_value_ids': example['neg_value_ids'][start_idx:], \"relation\": relation}\n",
    "        out_examples.append(out_example)\n",
    "        \n",
    "    with open(fn, \"w\") as fout:\n",
    "        for example in out_examples:\n",
    "            fout.write(ujson.dumps(example) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2122651d-daaa-485a-a204-67b1bd2d937c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31637 /home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/zero_shot/sequential_train_test_hlen_4_bm25/sim_rec_sequential.trels.tsv\n",
      "0\tQ0\t1042730\t1\n",
      "1\tQ0\t2054815\t1\n",
      "2\tQ0\t2054815\t1\n",
      "3\tQ0\t2024162\t1\n",
      "4\tQ0\t2024162\t1\n",
      "===========================================================================\n",
      "29658 /home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/zero_shot/sequential_train_test_hlen_4_bm25/search_sequential.test.json\n",
      "{\"uid\":76,\"query_ids\":[2475509,2536403,2987930,3008398],\"context_key_ids\":[2483941,2475509,2536403,2987930],\"context_value_ids\":[102099,490215,534086,157105],\"relation\":\"is_relevant_to\",\"test_id\":0}\n",
      "{\"uid\":76,\"query_ids\":[2483941,2475509,2536403,2987930],\"context_key_ids\":[2654742,2483941,2475509,2536403],\"context_value_ids\":[266488,102099,490215,534086],\"relation\":\"is_relevant_to\",\"test_id\":1}\n",
      "{\"uid\":76,\"query_ids\":[2654742,2483941,2475509,2536403],\"context_key_ids\":[2824399,2654742,2483941,2475509],\"context_value_ids\":[1121930,266488,102099,490215],\"relation\":\"is_relevant_to\",\"test_id\":2}\n",
      "{\"uid\":112,\"query_ids\":[2298242,2840926,2822857,3174679],\"context_key_ids\":[2577708,2298242,2840926,2822857],\"context_value_ids\":[521710,1882834,1695188,126317],\"relation\":\"is_relevant_to\",\"test_id\":3}\n",
      "{\"uid\":112,\"query_ids\":[2577708,2298242,2840926,2822857],\"context_key_ids\":[2915922,2577708,2298242,2840926],\"context_value_ids\":[2068019,521710,1882834,1695188],\"relation\":\"is_relevant_to\",\"test_id\":4}\n",
      "===========================================================================\n",
      "7058 /home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/zero_shot/sequential_train_test_hlen_4_bm25/compl_rec_sequential.trels.tsv\n",
      "0\tQ0\t2087293\t1\n",
      "0\tQ0\t1892525\t1\n",
      "1\tQ0\t733076\t1\n",
      "1\tQ0\t725602\t1\n",
      "2\tQ0\t725602\t1\n",
      "===========================================================================\n",
      "36487 /home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/zero_shot/sequential_train_test_hlen_4_bm25/search_sequential.trels.tsv\n",
      "0\tQ0\t1014120\t1\n",
      "1\tQ0\t786050\t1\n",
      "1\tQ0\t845098\t1\n",
      "1\tQ0\t157105\t1\n",
      "1\tQ0\t285420\t1\n",
      "===========================================================================\n",
      "3612 /home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/zero_shot/sequential_train_test_hlen_4_bm25/compl_rec_sequential.test.json\n",
      "{\"uid\":6,\"query_ids\":[2237551,2237551,986063,1040357],\"context_key_ids\":[1040357,2237551,2237551,986063],\"context_value_ids\":[2087293,725602,986063,733076],\"relation\":\"is_complementary_to\",\"test_id\":0}\n",
      "{\"uid\":6,\"query_ids\":[1040357,2237551,2237551,986063],\"context_key_ids\":[1040357,1040357,2237551,2237551],\"context_value_ids\":[1892525,2087293,725602,986063],\"relation\":\"is_complementary_to\",\"test_id\":1}\n",
      "{\"uid\":6,\"query_ids\":[1040357,2237551,2237551],\"context_key_ids\":[1040357,1040357,2237551],\"context_value_ids\":[1892525,2087293,725602],\"relation\":\"is_complementary_to\",\"test_id\":2}\n",
      "{\"uid\":212,\"query_ids\":[1949976,1490067,1065883,2216303],\"context_key_ids\":[2190671,1949976,1490067,1065883],\"context_value_ids\":[1902654,803750,2216303,2216303],\"relation\":\"is_complementary_to\",\"test_id\":3}\n",
      "{\"uid\":212,\"query_ids\":[1949976,1490067,1065883],\"context_key_ids\":[2190671,1949976,1490067],\"context_value_ids\":[1902654,803750,2216303],\"relation\":\"is_complementary_to\",\"test_id\":4}\n",
      "===========================================================================\n",
      "22884 /home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/zero_shot/sequential_train_test_hlen_4_bm25/sim_rec_sequential.test.json\n",
      "{\"uid\":211,\"query_ids\":[1938671,1938671,2172629,1595941],\"context_key_ids\":[841737,1938671,1938671,2172629],\"context_value_ids\":[713893,2054815,2054815,2054815],\"relation\":\"is_similar_to\",\"test_id\":0}\n",
      "{\"uid\":211,\"query_ids\":[841737,1938671,1938671,2172629],\"context_key_ids\":[1223138,841737,1938671,1938671],\"context_value_ids\":[187543,713893,2054815,2054815],\"relation\":\"is_similar_to\",\"test_id\":1}\n",
      "{\"uid\":211,\"query_ids\":[1223138,841737,1938671,1938671],\"context_key_ids\":[1707153,1223138,841737,1938671],\"context_value_ids\":[187543,187543,713893,2054815],\"relation\":\"is_similar_to\",\"test_id\":2}\n",
      "{\"uid\":255,\"query_ids\":[27394,1471299,335936,335936],\"context_key_ids\":[49512,27394,1471299,335936],\"context_value_ids\":[2024162,2024162,2024162,2024162],\"relation\":\"is_similar_to\",\"test_id\":3}\n",
      "{\"uid\":255,\"query_ids\":[49512,27394,1471299,335936],\"context_key_ids\":[49512,49512,27394,1471299],\"context_value_ids\":[597503,2024162,2024162,2024162],\"relation\":\"is_similar_to\",\"test_id\":4}\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "for fn in os.listdir(dest_dir):\n",
    "    fn = os.path.join(dest_dir, fn)\n",
    "    if fn.endswith(\".test.json\"):\n",
    "        continue\n",
    "    ! wc -l $fn\n",
    "    ! head -n 5 $fn\n",
    "    print(75*\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "597d0068-e046-4478-a4c2-ea1886e9b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uid': 211, 'query_ids': [455596, 1890709, 1890709, 1223138, 1223138, 1707153, 1223138, 841737, 1938671, 1938671, 2172629, 1595941], 'context_key_ids': [1403791, 455596, 1890709, 1890709, 1223138, 1223138, 1707153, 1223138, 841737, 1938671, 1938671, 2172629], 'context_value_ids': [662654, 187543, 187543, 187543, 187543, 187543, 187543, 187543, 713893, 2054815, 2054815, 2054815], 'target_value_ids': [[187543], [187543], [187543], [187543], [187543], [187543, 1223138], [187543], [713893], [2054815], [2054815], [2054815], [1042730]]}\n",
      "query: Pit Boss Pit Boss Pro Series 4 Series Vertical Smoker ; Pellet Smokers\n",
      "target_item: Eaton 15-Amp Residential Duplex Outlet, White ; Electrical Outlets\n",
      "neg_item: RACO Gray Metal New Work Deep Square Ceiling/Wall Electrical Box ; Electrical Boxes\n",
      "\n",
      "===========================================================================\n",
      "query: Pit Boss Pit Boss Pro Series 4 Series Vertical Smoker ; Pellet Smokers\n",
      "target_item: Eaton 15-Amp Residential Duplex Outlet, White ; Electrical Outlets\n",
      "neg_item: CARLON 4-Gang Blue Plastic New Work Standard Rectangular Wall Electrical Box ; Electrical Boxes\n",
      "\n",
      "===========================================================================\n",
      "query: Pit Boss Meat Probe 2-Pack Stainless Steel Accessory Kit ; Grilling Tools & Utensils\n",
      "target_item:  3/8-in x 4-ft x 8-ft Rated Pine Plywood Sheathing ; Plywood\n",
      "neg_item: ECARPETGALLERY Faux Fur Plush 2 x 3 Faux Fur Black Indoor Solid Bohemian/Eclectic Throw Rug ; Rugs\n",
      "\n",
      "===========================================================================\n",
      "query: Mr. Heater Buddy heaters 9000-BTU Outdoor Portable Radiant Propane Heater ; Propane Heaters\n",
      "target_item: EZ-FLO 1/2-in ID x 10-ft PVC Clear Vinyl Tubing ; Tubing & Hoses\n",
      "neg_item: Pure Enrichment HUME Ultrasonic Cool Mist Humidifier 0.92-Gallon Tabletop Cool Mist Humidifier (For Rooms 151-400-sq ft) ; Humidifiers\n",
      "\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "uid = 211\n",
    "for example in test_sim_examples:\n",
    "    if example[\"uid\"] == uid:\n",
    "        print(example)\n",
    "query_ids = [2237551,2237551,986063,1040357]\n",
    "target_vids = [1666533,1666533,257280,1452546]\n",
    "neg_vids = [2088791,828212,1127530,1943751]\n",
    "\n",
    "for qid, tvid, nvid in zip(query_ids, target_vids, neg_vids):\n",
    "    print(\"query: {}\\ntarget_item: {}\\nneg_item: {}\\n\".format(eid_to_text[qid], eid_to_text[tvid], eid_to_text[nvid]))\n",
    "    print(75*\"=\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7014e-f716-4f79-bd3d-7745a10b171b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "9c9569641937ce4addf5496cbe81a89e9d276a9857e7a9967fd6589fdce30733"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
