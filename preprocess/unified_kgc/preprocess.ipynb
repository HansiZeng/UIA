{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c97d205-f672-4866-b0fb-eebf185e5797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "client = bigquery.Client()\n",
    "print(\"Client creating using default project: {}\".format(client.project))\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM `gcp-ushi-digital-ds-qa.new_hansi_dataset.comp_rec_ClicksData_2core`;\n",
    "    \"\"\"\n",
    "query_job = client.query(query)\n",
    "compl_rec_df = query_job.to_dataframe()\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM `gcp-ushi-digital-ds-qa.new_hansi_dataset.hansi_rec_ClicksData_5core`;\n",
    "    \"\"\"\n",
    "query_job = client.query(query)\n",
    "sim_rec_df = query_job.to_dataframe()\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `gcp-ushi-digital-ds-qa.new_hansi_dataset.search_ClicksData_1year_5core`;\n",
    "\"\"\"\n",
    "query_job = client.query(query)\n",
    "search_df = query_job.to_dataframe()\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM `gcp-ushi-digital-ds-qa.hansi_dataset.all_products_info`;\n",
    "    \"\"\"\n",
    "query_job = client.query(query)\n",
    "product_df = query_job.to_dataframe()\n",
    "print(\"product_df = {:,}\".format(len(product_df)))\n",
    "\n",
    "all_products = set(product_df.product_id)\n",
    "anchors = set(compl_rec_df.anchor)\n",
    "compl_ivms = set(compl_rec_df.ivm)\n",
    "all_compl_ivms = anchors.union(compl_ivms)\n",
    "\n",
    "print(\"================================ For anchor_to_compl_ivms: ===================================\")\n",
    "print(\"number of unique product = {:,}, anchors = {:,}, complementary_compl_ivms = {:,}\".format(len(all_products), len(anchors), len(compl_ivms)))\n",
    "assert len(all_products & anchors) == len(anchors) and len(all_products & compl_ivms) == len(compl_ivms),(\n",
    "    len(all_products & anchors), len(anchors), len(all_products & compl_ivms), len(compl_ivms)\n",
    ")\n",
    "\n",
    "all_sim_ivms = set(sim_rec_df.anchor).union(set(sim_rec_df.ivm))\n",
    "print(\"================================ After updating anchor_to_similar_ivms: ===================================\")\n",
    "print(\"all_compl_ivms = {:,}, all_sim_ivms = {:,}\".format(len(all_compl_ivms), len(all_sim_ivms)))\n",
    "print(\"sim_compl_intersect = {:,} ({:.3f})\".format(len(all_compl_ivms & all_sim_ivms), len(all_compl_ivms & all_sim_ivms) / len(all_compl_ivms)))\n",
    "print(\"all_ivms = {:,}\".format(len(all_compl_ivms | all_sim_ivms)))\n",
    "all_ivms = all_compl_ivms | all_sim_ivms\n",
    "\n",
    "assert len(all_products & all_ivms) == len(all_ivms), (len(all_products & all_ivms), len(all_ivms))\n",
    "\n",
    "query_to_ivms = search_df.groupby(\"query\")[\"ivm\"].apply(list)\n",
    "ivm_to_tmp_queries = search_df.groupby(\"ivm\")[\"query\"].apply(list)\n",
    "query_lengths = np.array([len(x) for x in ivm_to_tmp_queries.values])\n",
    "all_queries = set(search_df[\"query\"])\n",
    "print(\"all queries = {:,}\".format(len(all_queries)))\n",
    "print(\"total ivms (queries) = {:,}, length >=3 = {:,}, length >= 5 = {:,}\".format(\n",
    "    len(query_lengths), np.sum(query_lengths >=3), np.sum(query_lengths >= 5) ))\n",
    "\n",
    "anchor_to_compl_ivms = compl_rec_df.groupby(\"anchor\")[\"ivm\"].apply(list)\n",
    "compl_ivms_length = np.array([len(x) for x in anchor_to_compl_ivms.values])\n",
    "print(\"================================ For anchor_to_compl_ivms: ===================================\")\n",
    "print(\"total_compl_ivms = {:,}, length >=3 = {:,}, length >= 5 = {:,}\".format(len(compl_ivms_length), np.sum(compl_ivms_length >=3), np.sum(compl_ivms_length >= 5) ))\n",
    "\n",
    "anchor_to_sim_ivms = sim_rec_df.groupby(\"anchor\")[\"ivm\"].apply(list)\n",
    "\n",
    "# map product --> text\n",
    "from tqdm import tqdm \n",
    "\n",
    "ivm_to_title = {}\n",
    "ivm_to_bullet = {}\n",
    "ivm_to_catalog = {}\n",
    "no_bulletin_ivms = set()\n",
    "no_title_ivms = set()\n",
    "no_catalog_ivms = set()\n",
    "\n",
    "def preprocess_text(in_text):\n",
    "    in_text = in_text.replace(\"\\t\", \" \")\n",
    "    in_text = in_text.replace(\"\\n\", \" \")\n",
    "    return in_text\n",
    "\n",
    "for idx, row in tqdm(product_df.iterrows(), total=len(product_df)):\n",
    "    product_id = row.product_id\n",
    "    title = row.product_name if row.product_name != None else \"No title\"\n",
    "    bullets = row.bullets if row.bullets != None else \"No bullets\"\n",
    "    catalog = row.catalog_name if row.catalog_name != None else \"No catalog\"\n",
    "    \n",
    "    if row.product_name == None:\n",
    "        no_title_ivms.add(product_id)\n",
    "    if row.bullets == None:\n",
    "        no_bulletin_ivms.add(product_id)\n",
    "    if row.catalog_name == None:\n",
    "        no_catalog_ivms.add(product_id)\n",
    "    \n",
    "    title = preprocess_text(title)\n",
    "    bullets = preprocess_text(bullets)\n",
    "    catalog = preprocess_text(catalog)\n",
    "    \n",
    "    ivm_to_title[product_id] = title\n",
    "    ivm_to_bullet[product_id] = bullets\n",
    "    ivm_to_catalog[product_id] = catalog\n",
    "\n",
    "# sanity check\n",
    "print(\"ivm_to_title = {:,}, ivm_to_bullet = {:,}, ivm_to_catalog = {:,}, products no bulletin = {:,}, no title = {:,}, no catalog = {:,}\".format(\n",
    "    len(ivm_to_title), len(ivm_to_bullet), len(ivm_to_catalog), len(no_bulletin_ivms), len(no_title_ivms), len(no_catalog_ivms)\n",
    "))\n",
    "\n",
    "assert len(ivm_to_title) == len(ivm_to_bullet) == len(ivm_to_catalog) == len(product_df)\n",
    "\n",
    "import ujson\n",
    "from collections import defaultdict\n",
    "\n",
    "# map to pid and qid\n",
    "ivm_to_pid = {ivm: pid for pid, ivm in enumerate(list(all_products))}\n",
    "pid_to_ivm = {pid: ivm for ivm, pid in ivm_to_pid.items()}\n",
    "query_to_qid = {query: qid + len(ivm_to_pid) for qid, query in enumerate(list(all_queries))}\n",
    "qid_to_query = {qid: query for query, qid in query_to_qid.items()}\n",
    "start_qid = len(ivm_to_pid)\n",
    "\n",
    "pid_to_title = {ivm_to_pid[ivm]: title for ivm, title in ivm_to_title.items()}\n",
    "pid_to_bullet = {ivm_to_pid[ivm]: bullet for ivm, bullet in ivm_to_bullet.items()}\n",
    "pid_to_catalog = {ivm_to_pid[ivm]: catalog for ivm, catalog in ivm_to_catalog.items()}\n",
    "\n",
    "aid_to_sim_pids = {ivm_to_pid[anchor]: [ivm_to_pid[ivm] for ivm in sim_ivms] for anchor, sim_ivms in anchor_to_sim_ivms.items()}\n",
    "aid_to_compl_pids = {ivm_to_pid[anchor]: [ivm_to_pid[ivm] for ivm in compl_ivms] for anchor, compl_ivms in anchor_to_compl_ivms.items()}\n",
    "qid_to_pids = {query_to_qid[query]: [ivm_to_pid[ivm] for ivm in ivms] for query, ivms in query_to_ivms.items()}\n",
    "pid_to_tmp_qids = {ivm_to_pid[ivm]: [query_to_qid[_query] for _query in queries] for ivm, queries in ivm_to_tmp_queries.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c11ad-080d-4331-9f4c-4b19c4fce16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to disk\n",
    "import os \n",
    "import copy\n",
    "import pickle\n",
    "\n",
    "out_dir = \"/home/jupyter/jointly_rec_and_search/datasets/unified_kgc/\"\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "    \n",
    "with open(os.path.join(out_dir, \"collection_title.tsv\"), \"w\") as fout:\n",
    "    for pid, title in pid_to_title.items():\n",
    "        fout.write(f\"{pid}\\t{title}\\n\")\n",
    "        \n",
    "with open(os.path.join(out_dir, \"collection_bullet.tsv\"), \"w\") as fout:\n",
    "    for pid, bullet in pid_to_bullet.items():\n",
    "        fout.write(f\"{pid}\\t{bullet}\\n\")\n",
    "        \n",
    "with open(os.path.join(out_dir, \"collection_catalog.tsv\"), \"w\") as fout:\n",
    "    for pid, catalog in pid_to_catalog.items():\n",
    "        fout.write(f\"{pid}\\t{catalog}\\n\")\n",
    "        \n",
    "        \n",
    "with open(os.path.join(out_dir, \"product.jsonl\"), \"w\") as fout:\n",
    "    with open(os.path.join(out_dir, \"collection_title_catalog.tsv\"), \"w\") as fout2:\n",
    "        for aid in pid_to_title:\n",
    "            text = pid_to_title[aid] + \" ; \" +  pid_to_catalog[aid]\n",
    "            example = {\"id\": aid, \"contents\": text}\n",
    "            fout.write(ujson.dumps(example) + \"\\n\")\n",
    "            fout2.write(f\"{aid}\\t{text}\\n\")\n",
    "            \n",
    "with open(os.path.join(out_dir, \"all_queries.tsv\"), \"w\") as fout:\n",
    "    for query, qid in query_to_qid.items():\n",
    "        fout.write(f\"{qid}\\t{query}\\n\")\n",
    "            \n",
    "with open(os.path.join(out_dir, \"all_entities.tsv\"), \"w\") as fout:\n",
    "    for aid in pid_to_title:\n",
    "        text = pid_to_title[aid] + \" ; \" +  pid_to_catalog[aid]\n",
    "        fout.write(f\"{aid}\\t{text}\\n\")\n",
    "    for query, qid in query_to_qid.items():\n",
    "        fout.write(f\"{qid}\\t{query}\\n\")\n",
    "        \n",
    "with open(os.path.join(out_dir, \"ivm_to_pid.pkl\"), \"wb\") as fout:\n",
    "    pickle.dump(ivm_to_pid, fout)\n",
    "\n",
    "with open(os.path.join(out_dir, \"query_to_qid.pkl\"), \"wb\") as fout:\n",
    "    pickle.dump(query_to_qid, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869ff591-a27e-406b-b919-efd5de39372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "for path in os.listdir(out_dir):\n",
    "    path = os.path.join(out_dir, path)\n",
    "    ! wc -l $path\n",
    "    ! head -n 3 $path\n",
    "    ! tail -n 3 $path\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2556bbc7-2f42-499e-98bb-84e889e4e132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
