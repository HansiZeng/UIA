{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ca3995-6c37-409a-9ade-8298335f0492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "in_dir = \"/home/jupyter/unity_jointly_rec_and_search/datasets/spotify_mpd/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d705f173-4461-41cc-9d14-22a03864de5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of aid_to_simpids  train = 391,094, test = 48,869\n",
      "number of qid_to_pids train = 393,188, test = 49,149\n"
     ]
    }
   ],
   "source": [
    "# start create graph\n",
    "\n",
    "import random \n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "\n",
    "fns = [\"train_aid_to_simpids.pkl\", \"test_aid_to_simpids.pkl\",\n",
    "      \"train_qid_to_relpids.pkl\", \"test_qid_to_relpids.pkl\"]\n",
    "\n",
    "datas = []\n",
    "for fn in fns:\n",
    "    fn = os.path.join(in_dir, fn)\n",
    "    with open(fn, \"rb\") as fin:\n",
    "        datas.append(pickle.load(fin))\n",
    "\n",
    "train_aid_to_simpids, test_aid_to_simpids,\\\n",
    "train_qid_to_pids, test_qid_to_pids = datas\n",
    "print(\"number of aid_to_simpids  train = {:,}, test = {:,}\".format(len(train_aid_to_simpids), \n",
    "                                                                     len(test_aid_to_simpids)))\n",
    "print(\"number of qid_to_pids train = {:,}, test = {:,}\".format(len(train_qid_to_pids), \n",
    "                                                                      len(test_qid_to_pids)))\n",
    "\n",
    "assert len( set(train_aid_to_simpids.keys()) &  set(test_aid_to_simpids.keys()) ) == 0\n",
    "assert len( set(train_qid_to_pids.keys())  & set(test_qid_to_pids.keys())) == 0\n",
    "\n",
    "SIM_RELATION = \"also_contains\"\n",
    "REL_RELATION = \"is_relevant_to\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7641ddd-5a3f-4423-b0b5-90cf59e36b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max pids = 2256247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\neid_to_text = {}\\nwith open(os.path.join(in_dir, \"all_entities.tsv\")) as fin:\\n    for line in fin:\\n        eid, text = line.strip().split(\"\\t\")\\n        eid_to_text[int(eid)] = text\\n\\nrun_path = os.path.join(in_dir, \"runs/bm25.all.run\")\\nbm25_hid_to_tids = defaultdict(list)\\nwith open(run_path) as fin:\\n    for line in fin:\\n        array = line.strip().split(\" \")\\n        assert len(array) == 6\\n        hid, tid = int(array[0]), int(array[2])\\n        if hid in train_qid_to_pids or hid in train_aid_to_simpids:\\n            bm25_hid_to_tids[hid].append(tid)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIDS = []\n",
    "with open(os.path.join(in_dir, \"all_tracks.tsv\")) as fin:\n",
    "    for line in fin:\n",
    "        PIDS.append(int(line.strip().split(\"\\t\")[0]))\n",
    "print(f\"max pids = {max(PIDS)}\")\n",
    "assert len(PIDS) == len(set(PIDS))\n",
    "\n",
    "def create_triples(hid, pos_tid, miss_hids, duplicate_pairs, eid_to_text, sampler=None):\n",
    "    if sampler != None:\n",
    "        assert type(sampler) == dict or type(sampler) == defaultdict, type(sampler)\n",
    "        if hid not in sampler:\n",
    "            miss_hids.append(hid)\n",
    "            return 0\n",
    "    if eid_to_text[hid] == eid_to_text[pos_tid]:\n",
    "        duplicate_pairs.append((hid, pos_tid))\n",
    "        return 0\n",
    "    \n",
    "    if sampler != None and len(sampler[hid]) > 10:\n",
    "        neg_tid = random.sample(sampler[hid], k=1)[0]\n",
    "        while neg_tid == pos_tid:\n",
    "            neg_tid = random.sample(sampler[hid], k=1)[0]\n",
    "    else:\n",
    "        neg_tid = random.sample(PIDS, k=1)[0]\n",
    "        while neg_tid == pos_tid:\n",
    "            neg_tid = random.sample(range(len(PIDS)), k=1)[0]\n",
    "            \n",
    "    return (hid, pos_tid, neg_tid)\n",
    "\n",
    "\n",
    "eid_to_text = {}\n",
    "with open(os.path.join(in_dir, \"all_entities.tsv\")) as fin:\n",
    "    for line in fin:\n",
    "        eid, text = line.strip().split(\"\\t\")\n",
    "        eid_to_text[int(eid)] = text\n",
    "\n",
    "run_path = os.path.join(in_dir, \"runs/bm25.all.run\")\n",
    "bm25_hid_to_tids = defaultdict(list)\n",
    "with open(run_path) as fin:\n",
    "    for line in fin:\n",
    "        array = line.strip().split(\" \")\n",
    "        assert len(array) == 6\n",
    "        hid, tid = int(array[0]), int(array[2])\n",
    "        if hid in train_qid_to_pids or hid in train_aid_to_simpids:\n",
    "            bm25_hid_to_tids[hid].append(tid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6e25e1c-27b1-408c-82a7-7226b3997c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 391094/391094 [01:25<00:00, 4571.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_hids = 0, duplicate_pairs = 0\n",
      "===========================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393188/393188 [01:36<00:00, 4090.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_hids = 438,366, duplicate_pairs = 0\n",
      "===========================================================================\n",
      "number of h2sp, q2p triples = 24,125,410, 25,638,010\n"
     ]
    }
   ],
   "source": [
    "miss_hids = []\n",
    "duplicate_pairs = []\n",
    "\n",
    "h2sp_triples = []\n",
    "q2p_triples = []\n",
    "for hid, tail_ids in tqdm(train_aid_to_simpids.items(), total=len(train_aid_to_simpids)):\n",
    "    for pos_tid in tail_ids:\n",
    "        triple = create_triples(hid, pos_tid, miss_hids, duplicate_pairs, eid_to_text)\n",
    "        if triple != 0:\n",
    "            h2sp_triples.append(triple)\n",
    "print(\"miss_hids = {:,}, duplicate_pairs = {:,}\".format(len(miss_hids), len(duplicate_pairs)))\n",
    "print(\"=\"*75)\n",
    "for qid, pos_pids in tqdm(train_qid_to_pids.items(), total=len(train_qid_to_pids)):\n",
    "    for pos_pid in pos_pids:\n",
    "        triple = create_triples(qid, pos_pid, miss_hids, duplicate_pairs, eid_to_text, sampler=bm25_hid_to_tids)\n",
    "        if triple != 0:\n",
    "            q2p_triples.append(triple)\n",
    "print(\"miss_hids = {:,}, duplicate_pairs = {:,}\".format(len(miss_hids), len(duplicate_pairs)))\n",
    "print(\"=\"*75)\n",
    "\n",
    "print(\"number of h2sp, q2p triples = {:,}, {:,}\".format(\n",
    "    len(h2sp_triples), len(q2p_triples)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2951ab78-320d-474e-9b61-ab7d7dc7b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "kgc_dir = in_dir\n",
    "out_dir = os.path.join(kgc_dir, \"unified_train/\")\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "    \n",
    "h2sp_triples = random.sample(h2sp_triples, k=600_000)\n",
    "q2p_triples = random.sample(q2p_triples, k=600_000)\n",
    "\n",
    "fn_to_tripleNrel = {\n",
    "    \"a2sp.train.tsv\": (h2sp_triples, SIM_RELATION),\n",
    "    \"q2p.train.tsv\": (q2p_triples, REL_RELATION),   \n",
    "}\n",
    "\n",
    "for fn, (triples, relation) in fn_to_tripleNrel.items():\n",
    "    with open(os.path.join(out_dir, fn), \"w\") as fout:\n",
    "        for (hid, pos_tid, neg_tid) in triples:\n",
    "            fout.write(f\"{hid}\\t{pos_tid}\\t{neg_tid}\\t{relation}\\n\")\n",
    "            \n",
    "out_dir = os.path.join(kgc_dir, \"unified_test/\")\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "# for similar items\n",
    "fn_to_aids = {\n",
    "    \"anchors.test.sim.tsv\": list(test_aid_to_simpids.keys()),\n",
    "    \"anchors.test.sim.small.tsv\": random.sample(list(test_aid_to_simpids.keys()), k=10_000),\n",
    "}\n",
    "for fn, aids in fn_to_aids.items():\n",
    "    with open(os.path.join(out_dir, fn), \"w\") as fout:\n",
    "        for aid in aids:\n",
    "            text = eid_to_text[aid]\n",
    "            fout.write(f\"{aid}\\t{text}\\t{SIM_RELATION}\\n\")\n",
    "            \n",
    "fn_to_arels = {\n",
    "    \"arels.test.sim.tsv\": [(aid, pid) for aid, simpids in test_aid_to_simpids.items() for pid in simpids],\n",
    "}\n",
    "for fn, arels in fn_to_arels.items():\n",
    "    with open(os.path.join(out_dir, fn), \"w\") as fout:\n",
    "        for (aid, pid) in arels:\n",
    "            fout.write(f\"{aid}\\tQ0\\t{pid}\\t{1}\\n\")\n",
    "            \n",
    "# for queries\n",
    "fn_to_qids = {\n",
    "    \"queries.test.tsv\": list(test_qid_to_pids.keys()),\n",
    "    \"queries.test.small.tsv\": random.sample(test_qid_to_pids.keys(), k=10_000)\n",
    "}\n",
    "for fn, qids in fn_to_qids.items():\n",
    "    with open(os.path.join(out_dir, fn), \"w\") as fout:\n",
    "        for qid in qids:\n",
    "            text = eid_to_text[qid]\n",
    "            fout.write(f\"{qid}\\t{text}\\t{REL_RELATION}\\n\")\n",
    "fn_to_qrels = {\n",
    "    \"qrels.test.tsv\": [(qid, pid) for (qid, pids) in test_qid_to_pids.items() for pid in pids],\n",
    "}\n",
    "for fn, qrels in fn_to_qrels.items():\n",
    "    with open(os.path.join(out_dir, fn), \"w\") as fout:\n",
    "        for (qid, pid) in qrels:\n",
    "            fout.write(f\"{qid}\\tQ0\\t{pid}\\t{1}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfa7598f-2c00-46f7-baa1-2dae0ef8baf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600000 /home/jupyter/unity_jointly_rec_and_search/datasets/spotify_mpd/processed/unified_train/q2p.train.tsv\n",
      "2637595\t115507\t961223\tis_relevant_to\n",
      "2994756\t24198\t1070713\tis_relevant_to\n",
      "3080908\t42698\t1044471\tis_relevant_to\n",
      "2985700\t31379\t1693708\tis_relevant_to\n",
      "3201060\t88837\t2159403\tis_relevant_to\n",
      "2944609\t3550\t400858\tis_relevant_to\n",
      "====================================================================================================\n",
      "600000 /home/jupyter/unity_jointly_rec_and_search/datasets/spotify_mpd/processed/unified_train/a2sp.train.tsv\n",
      "997328\t21976\t1083169\talso_contains\n",
      "1037363\t124411\t407725\talso_contains\n",
      "1064371\t4148\t1086020\talso_contains\n",
      "1072270\t13161\t615525\talso_contains\n",
      "1208546\t502581\t1176215\talso_contains\n",
      "1307573\t22020\t994042\talso_contains\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "out_dir = os.path.join(kgc_dir, \"unified_train/\")\n",
    "for path in os.listdir(out_dir):\n",
    "    path = os.path.join(out_dir, path)\n",
    "    ! wc -l $path\n",
    "    ! head -n 3 $path\n",
    "    ! tail -n 3 $path\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c9ddcb9-fe82-452f-bf1d-6c53b3f27b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1037363 The playlist contains tracks: Track name is Setting Fires in the album Setting Fires by the artist The Chainsmokers ; Track name is Closer in the album Closer by the artist The Chainsmokers ; Track name is Inside Out in the album Inside Out by the artist The Chainsmokers ; Track name is Don't Let Me Down in the album The Chainsmokers- Japan Special Edition by the artist The Chainsmokers ; Track name is Let Me Hold You (Turn Me On) in the album Let Me Hold You (Turn Me On) by the artist Dante Klein ;\n",
      "124411 Track name is Sapient Dream in the album Brain Freeze by the artist Slushii\n",
      "407725 Track name is Push - Radio Mix in the album Push by the artist Cannavo & Nesse\n"
     ]
    }
   ],
   "source": [
    "hid, pos_tid, neg_tid = (1037363,124411,407725)\n",
    "print(hid, eid_to_text[hid])\n",
    "print(pos_tid, eid_to_text[pos_tid])\n",
    "print(neg_tid, eid_to_text[neg_tid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "31517e15-b4be-4a48-817c-82d2768875ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_fn: /home/jupyter/unity_jointly_rec_and_search/datasets/unified_kgc/unified_test/arels.test.sim.tsv, size: 8,273\n",
      "train_fn: /home/jupyter/unity_jointly_rec_and_search/datasets/unified_kgc/unified_train/a2sp.train.tsv, size: 199,507\n",
      "===========================================================================\n",
      "test_fn: /home/jupyter/unity_jointly_rec_and_search/datasets/unified_kgc/unified_test/arels.test.compl.tsv, size: 6,720\n",
      "train_fn: /home/jupyter/unity_jointly_rec_and_search/datasets/unified_kgc/unified_train/a2cp.train.tsv, size: 80,042\n",
      "===========================================================================\n",
      "test_fn: /home/jupyter/unity_jointly_rec_and_search/datasets/unified_kgc/unified_test/qrels.test.tsv, size: 7,274\n",
      "train_fn: /home/jupyter/unity_jointly_rec_and_search/datasets/unified_kgc/unified_train/max2_qorient_q2p.train.tsv, size: 832,482\n",
      "===========================================================================\n",
      "SUCCESS: test and train qids not overlap.\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "import os\n",
    "\n",
    "#test_dir = os.path.join(in_dir, \"selected_test_user\")\n",
    "kgc_dir = \"/home/jupyter/unity_jointly_rec_and_search/datasets/unified_kgc/\"\n",
    "\n",
    "test_fns = [\n",
    "    os.path.join(kgc_dir, \"unified_test/arels.test.sim.tsv\"),\n",
    "    os.path.join(kgc_dir, \"unified_test/arels.test.compl.tsv\"),\n",
    "    os.path.join(kgc_dir, \"unified_test/qrels.test.tsv\")\n",
    "]\n",
    "train_fns = [\n",
    "    os.path.join(kgc_dir, \"unified_train/a2sp.train.tsv\"),\n",
    "    os.path.join(kgc_dir, \"unified_train/a2cp.train.tsv\"),\n",
    "    os.path.join(kgc_dir, \"unified_train/max2_qorient_q2p.train.tsv\")\n",
    "]\n",
    "\n",
    "for test_fn, train_fn in zip(test_fns, train_fns):\n",
    "    test_qids, train_qids = set(), set()\n",
    "    with open(test_fn) as fin:\n",
    "        for line in fin:\n",
    "            array = line.rstrip().split(\"\\t\")\n",
    "            assert len(array) == 4\n",
    "            test_qids.add(array[0])\n",
    "    with open(train_fn) as fin:\n",
    "        for line in fin:\n",
    "            array = line.rstrip().split(\"\\t\")\n",
    "            assert len(array) == 4\n",
    "            train_qids.add(array[0])\n",
    "    assert len(test_qids & train_qids) == 0\n",
    "    print(f\"test_fn: {test_fn}, size: {len(test_qids):,}\")\n",
    "    print(f\"train_fn: {train_fn}, size: {len(train_qids):,}\")\n",
    "    print(75*\"=\")\n",
    "print(\"SUCCESS: test and train qids not overlap.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c58cf1-6f96-470f-a4fd-8ee27a2e498b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
