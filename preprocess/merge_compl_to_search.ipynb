{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15b75103-1c3d-4ac9-ae04-c2e1c4e24f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client creating using default project: gcp-ushi-digital-ds-qa\n",
      "product_df = 2,260,878\n",
      "number of unique product = 2260878, ivms = 159380, similar_ivms = 76572\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "client = bigquery.Client()\n",
    "print(\"Client creating using default project: {}\".format(client.project))\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM `gcp-ushi-digital-ds-qa.new_hansi_dataset.search_ClicksData_w_core_sim_ivms_and_comp_ivms`;\n",
    "    \"\"\"\n",
    "query_job = client.query(query)\n",
    "search_df = query_job.to_dataframe()\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT * \n",
    "    FROM `gcp-ushi-digital-ds-qa.hansi_dataset.all_products_info`;\n",
    "    \"\"\"\n",
    "query_job = client.query(query)\n",
    "product_df = query_job.to_dataframe()\n",
    "print(\"product_df = {:,}\".format(len(product_df)))\n",
    "\n",
    "all_products = set(product_df.product_id)\n",
    "similar_ivms = set(np.concatenate(list(search_df.similar_ivms.values)))\n",
    "ivms = set(search_df.ivm.values)\n",
    "\n",
    "print(\"number of unique product = {}, ivms = {}, similar_ivms = {}\".format(len(all_products), len(ivms), len(similar_ivms)))\n",
    "assert len(all_products & similar_ivms) == len(similar_ivms) and len(all_products & ivms) == len(ivms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4211513-3879-4b01-a44a-9941f9bc55dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sep token = [SEP]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2260878/2260878 [03:14<00:00, 11645.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_to_title and _to_text = 2,260,878, 2,260,878, no bulletin product = 0, no title product = 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# map product --> text\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "print(\"sep token = {}\".format(tokenizer.sep_token))\n",
    "from tqdm import tqdm \n",
    "\n",
    "product_to_title = {}\n",
    "product_to_text = {}\n",
    "no_bulletin_product = set()\n",
    "no_title_product = set()\n",
    "\n",
    "def preprocess_text(in_text):\n",
    "    in_text = in_text.replace(\"\\t\", \" \")\n",
    "    in_text = in_text.replace(\"\\n\", \" \")\n",
    "    return in_text\n",
    "\n",
    "for idx, row in tqdm(product_df.iterrows(), total=len(product_df)):\n",
    "    product_id = row.product_id\n",
    "    title = row.product_name if row.product_name != None else \"No title\"\n",
    "    bullets = row.bullets if row.bullets != None else \"No bullets\"\n",
    "    \n",
    "    if row.product_name == None:\n",
    "        no_title_product.add(product_id)\n",
    "    if row.bullets == None:\n",
    "        no_bulletin_product.add(product_id)\n",
    "    \n",
    "    title = preprocess_text(title)\n",
    "    bullets = preprocess_text(bullets)\n",
    "    prd_text = title + \" \" + tokenizer.sep_token + \" \" + bullets\n",
    "    assert \"\\t\" not in prd_text and \"\\n\" not in prd_text, prd_text\n",
    "    \n",
    "    product_to_title[product_id] = title\n",
    "    product_to_text[product_id] = prd_text\n",
    "\n",
    "# sanity check\n",
    "print(\"product_to_title and _to_text = {:,}, {:,}, no bulletin product = {:,}, no title product = {:,}\".format(\n",
    "    len(product_to_title), len(product_to_text), len(no_bulletin_product), len(no_title_product)\n",
    "))\n",
    "\n",
    "assert len(product_to_title) == len(product_to_text) and len(product_to_text) == len(product_df), (len(product_to_text), len(product_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae30cc83-4a92-4edd-8b07-6d273945eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map: product --> pid, query --> qid\n",
    "all_uni_queries = np.unique(search_df[\"query\"])\n",
    "\n",
    "query_to_qid = {query: qid for qid, query in enumerate(all_uni_queries)}\n",
    "product_to_pid = {product_id: pid for pid, product_id in enumerate(all_products)} \n",
    "pid_to_title = {product_to_pid[product_id]: title for product_id, title in product_to_title.items()}\n",
    "pid_to_text = {product_to_pid[product_id]: text for product_id, text in product_to_text.items()}\n",
    "\n",
    "assert len(pid_to_text) == len(pid_to_text) == len(product_to_text) == len(product_to_title)\n",
    "\n",
    "qid_to_query = {qid: query for query, qid in query_to_qid.items()}\n",
    "assert len(qid_to_query) == len(query_to_qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09a2c858-c3f7-45d8-aba1-287ac909dd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of anchor_ivms = 83440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 915725/915725 [00:38<00:00, 23694.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# read all anchor_ivm from train_qrel\n",
    "anchor_ivms = set()\n",
    "in_dir = \"/home/jupyter/jointly_rec_and_search/datasets/rec_search/search/\"\n",
    "pid_to_productid = {pid: product_id for product_id, pid in product_to_pid.items()}\n",
    "with open(os.path.join(in_dir, \"anchors.train.tsv\")) as fin:\n",
    "    for line in fin:\n",
    "        pid, _ = line.rstrip().split(\"\\t\")\n",
    "        product_id = pid_to_productid[int(pid)]\n",
    "        anchor_ivms.add(product_id)\n",
    "print(\"length of anchor_ivms = {}\".format(len(anchor_ivms)))\n",
    "\n",
    "anchor_to_compls = {}\n",
    "not_in_train = set()\n",
    "for idx, row in tqdm(search_df.iterrows(), total=len(search_df)):\n",
    "    a_ivm, compl_ivms = row[\"ivm\"], row[\"complement_ivms\"]\n",
    "    if len(compl_ivms) == 0:\n",
    "        continue \n",
    "    \n",
    "    if a_ivm not in anchor_ivms:\n",
    "        not_in_train.add(a_ivm)\n",
    "        continue \n",
    "    \n",
    "    for compl_ivm in compl_ivms:\n",
    "        if a_ivm not in anchor_to_compls:\n",
    "            anchor_to_compls[a_ivm] = set([compl_ivm])\n",
    "        else:\n",
    "            anchor_to_compls[a_ivm].add(compl_ivm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90d99f33-af00-4b48-a157-2fe5fa7abe97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1950, 8251)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anchor_to_compls), np.sum(len(xs) for _, xs in anchor_to_compls.items()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27cdd279-c611-4b63-ae58-05860f1599c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49568, 83440)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_in_train), len(anchor_ivms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1420ae-6fec-47f2-8d25-8c680d43e665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
