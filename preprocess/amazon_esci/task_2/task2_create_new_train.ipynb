{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17304e94-e9ef-4e3f-8bd6-13bf08c02015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 843496/843496 [00:04<00:00, 172645.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of edges = 2,746,193, number of multi-attr edges = 1,090, (0.000)\n",
      "max pids = 1216069\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "from collections import defaultdict\n",
    "import random \n",
    "\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "random.seed(4680)\n",
    "\n",
    "in_dir = \"/home/jupyter/unity_jointly_rec_and_search/datasets/amazon_esci_dataset/task_2_multiclass_product_classification/\"\n",
    "datas = []\n",
    "         \n",
    "fns = [\n",
    "    \"train_aid_to_simpids.pkl\",\n",
    "    \"train_aid_to_complpids.pkl\",\n",
    "    \"train_qid_to_relpids.pkl\",\n",
    "    ]\n",
    "for fn in fns:\n",
    "    with open(os.path.join(in_dir, fn), \"rb\") as fin:\n",
    "        datas.append(pkl.load(fin))\n",
    "\n",
    "train_aid_to_simpids, train_aid_to_complpids, train_qid_to_pids = datas\n",
    "\n",
    "G = nx.MultiDiGraph()\n",
    "SIM_RELATION = \"is_similar_to\"\n",
    "COMPL_RELATION = \"is_complementary_to\"\n",
    "REL_RELATION = \"is_relevant_to\"\n",
    "\n",
    "for aid, sim_pids in train_aid_to_simpids.items():\n",
    "    triples = [(aid, sim_pid, {\"type\":SIM_RELATION}) for sim_pid in sim_pids]\n",
    "    G.add_edges_from(triples)\n",
    "    \n",
    "for aid, compl_pids in train_aid_to_complpids.items():\n",
    "    triples = [(aid, compl_pid, {\"type\":COMPL_RELATION}) for compl_pid in compl_pids]\n",
    "    G.add_edges_from(triples)\n",
    "    \n",
    "for qid, pids in train_qid_to_pids.items():\n",
    "    triples = [(pid, qid, {\"type\": REL_RELATION}) for pid in pids]\n",
    "    G.add_edges_from(triples)\n",
    "    \n",
    "multi_edge_pairs = []\n",
    "for n, nbrs_dict in tqdm(G.adj.items(), total=G.number_of_nodes()):\n",
    "    for nbr_node, edge_attrs in nbrs_dict.items():\n",
    "        assert len(edge_attrs) == 1 or len(edge_attrs) == 2\n",
    "        if len(edge_attrs) == 2:\n",
    "            multi_edge_pairs.append((n, nbr_node))\n",
    "            \n",
    "print(\"number of edges = {:,}, number of multi-attr edges = {:,}, ({:.3f})\".format(G.number_of_edges(), len(multi_edge_pairs), \n",
    "                                                                                   len(multi_edge_pairs)/G.number_of_edges()))\n",
    "\n",
    "PIDS = []\n",
    "with open(os.path.join(in_dir, \"collection_title.tsv\")) as fin:\n",
    "    for line in fin:\n",
    "        PIDS.append(int(line.strip().split(\"\\t\")[0]))\n",
    "print(f\"max pids = {max(PIDS)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c520f50e-46d3-4a50-8c68-09d6ccdaf412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ignore hids = 2354\n"
     ]
    }
   ],
   "source": [
    "eid_to_text = {}\n",
    "with open(os.path.join(in_dir, \"all_entities.tsv\")) as fin:\n",
    "    for line in fin:\n",
    "        eid, text = line.strip().split(\"\\t\")\n",
    "        eid_to_text[int(eid)] = text\n",
    "        \n",
    "run_path = os.path.join(in_dir, \"runs/bm25.all.run\")\n",
    "df = pd.read_csv(run_path, sep=\" \", names=[\"hid\", \"q0\", \"tid\", \"rank\", \"score\", \"model_name\"])\n",
    "bm25_hid_to_tids = {}\n",
    "ignore_hids = set()\n",
    "for hid, group in df.groupby(\"hid\"):\n",
    "    cand_tids = list(group.tid.values)\n",
    "    if len(cand_tids) < 10:\n",
    "        ignore_hids.add(int(hid))\n",
    "    else:\n",
    "        bm25_hid_to_tids[int(hid)] = [int(x) for x in cand_tids]\n",
    "        \n",
    "print(\"number of ignore hids = {}\".format(len(ignore_hids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2870fd3d-476c-4d0e-af76-511ed6275a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "miss_hids = 3,701, triples with simnegs = 302,568, triples with complnegs = 31,493, triples with bm25negs = 266,506\n",
      "total triples = 600,567\n",
      "===========================================================================\n",
      "miss_hids = 2,820, triples with simnegs = 237,647, triples with complnegs = 24,020, triples with bm25negs = 190,415\n",
      "total triples = 452,082\n",
      "===========================================================================\n",
      "miss_hids = 1,593, triples with simnegs = 135,917, triples with complnegs = 13,282, triples with bm25negs = 100,182\n",
      "total triples = 249,381\n",
      "===========================================================================\n",
      "miss_hids = 698, triples with simnegs = 58,778, triples with complnegs = 5,707, triples with bm25negs = 41,421\n",
      "total triples = 105,906\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "MAX_PID = max(PIDS)\n",
    "def create_mixture_triples_for_search(hid, pos_tid, hid_to_simpids_sampler, hid_to_complpids_sampler, bm25_hid_to_tid_sampler,\n",
    "                                     miss_hids, hids_have_simnegs, hids_have_complnegs, hids_have_bm25negs):\n",
    "    if pos_tid in hid_to_simpids_sampler:\n",
    "        neg_tid = random.sample(hid_to_simpids_sampler[pos_tid], k=1)[0]\n",
    "        assert neg_tid != pos_tid\n",
    "        hids_have_simnegs.append(hid)\n",
    "    elif pos_tid in hid_to_complpids_sampler:\n",
    "        neg_tid = random.sample(hid_to_complpids_sampler[pos_tid], k=1)[0]\n",
    "        assert neg_tid != pos_tid\n",
    "        hids_have_complnegs.append(hid)\n",
    "    elif hid in bm25_hid_to_tid_sampler:\n",
    "        neg_tid = random.sample(bm25_hid_to_tid_sampler[hid], k=1)[0]\n",
    "        while neg_tid == pos_tid:\n",
    "            neg_tid = random.sample(bm25_hid_to_tid_sampler[hid], k=1)[0]\n",
    "        hids_have_bm25negs.append(hid)\n",
    "    else:\n",
    "        miss_hids.append(hid)\n",
    "        return 0 \n",
    "    \n",
    "    return (hid, pos_tid, neg_tid)\n",
    "\n",
    "max15_q2p = {}\n",
    "max10_q2p = {}\n",
    "max5_q2p = {}\n",
    "max2_q2p = {}\n",
    "\n",
    "max15_q2p_triples = []\n",
    "max10_q2p_triples = []\n",
    "max5_q2p_triples = []\n",
    "max2_q2p_triples = []\n",
    "for qid, pids in train_qid_to_pids.items():\n",
    "    max15_q2p[qid] = random.sample(pids, k=len(pids))[:15]\n",
    "    max10_q2p[qid] = random.sample(pids, k=len(pids))[:10]\n",
    "    max5_q2p[qid] = random.sample(pids, k=len(pids))[:5]\n",
    "    max2_q2p[qid] = random.sample(pids, k=len(pids))[:2]\n",
    "    \n",
    "miss_hids, hids_have_simnegs, hids_have_complnegs, hids_have_bm25negs = [], [], [], []\n",
    "total_triples = 0   \n",
    "for qid, pos_pids in max15_q2p.items():\n",
    "    for pos_pid in pos_pids:\n",
    "        triple = create_mixture_triples_for_search(qid, pos_pid, \n",
    "                                                   hid_to_simpids_sampler=train_aid_to_simpids,\n",
    "                                                   hid_to_complpids_sampler=train_aid_to_complpids, \n",
    "                                                   bm25_hid_to_tid_sampler=bm25_hid_to_tids,\n",
    "                                                   miss_hids=miss_hids, \n",
    "                                                   hids_have_simnegs=hids_have_simnegs, \n",
    "                                                   hids_have_complnegs=hids_have_complnegs, \n",
    "                                                   hids_have_bm25negs=hids_have_bm25negs)\n",
    "        if triple != 0:\n",
    "            max15_q2p_triples.append(triple)\n",
    "            total_triples += 1\n",
    "print(\"miss_hids = {:,}, triples with simnegs = {:,}, triples with complnegs = {:,}, triples with bm25negs = {:,}\".format(\n",
    "    len(miss_hids), len(hids_have_simnegs), len(hids_have_complnegs), len(hids_have_bm25negs)\n",
    "))\n",
    "print(\"total triples = {:,}\".format(total_triples))\n",
    "print(\"=\"*75)\n",
    "\n",
    "miss_hids, hids_have_simnegs, hids_have_complnegs, hids_have_bm25negs = [], [], [], []\n",
    "total_triples = 0   \n",
    "for qid, pos_pids in max10_q2p.items():\n",
    "    for pos_pid in pos_pids:\n",
    "        triple = create_mixture_triples_for_search(qid, pos_pid, \n",
    "                                                   hid_to_simpids_sampler=train_aid_to_simpids,\n",
    "                                                   hid_to_complpids_sampler=train_aid_to_complpids, \n",
    "                                                   bm25_hid_to_tid_sampler=bm25_hid_to_tids,\n",
    "                                                   miss_hids=miss_hids, \n",
    "                                                   hids_have_simnegs=hids_have_simnegs, \n",
    "                                                   hids_have_complnegs=hids_have_complnegs, \n",
    "                                                   hids_have_bm25negs=hids_have_bm25negs)\n",
    "        if triple != 0:\n",
    "            max10_q2p_triples.append(triple)\n",
    "            total_triples += 1\n",
    "print(\"miss_hids = {:,}, triples with simnegs = {:,}, triples with complnegs = {:,}, triples with bm25negs = {:,}\".format(\n",
    "    len(miss_hids), len(hids_have_simnegs), len(hids_have_complnegs), len(hids_have_bm25negs)\n",
    "))\n",
    "print(\"total triples = {:,}\".format(total_triples))\n",
    "print(\"=\"*75)\n",
    "\n",
    "miss_hids, hids_have_simnegs, hids_have_complnegs, hids_have_bm25negs = [], [], [], []\n",
    "total_triples = 0   \n",
    "for qid, pos_pids in max5_q2p.items():\n",
    "    for pos_pid in pos_pids:\n",
    "        triple = create_mixture_triples_for_search(qid, pos_pid, \n",
    "                                                   hid_to_simpids_sampler=train_aid_to_simpids,\n",
    "                                                   hid_to_complpids_sampler=train_aid_to_complpids, \n",
    "                                                   bm25_hid_to_tid_sampler=bm25_hid_to_tids,\n",
    "                                                   miss_hids=miss_hids, \n",
    "                                                   hids_have_simnegs=hids_have_simnegs, \n",
    "                                                   hids_have_complnegs=hids_have_complnegs, \n",
    "                                                   hids_have_bm25negs=hids_have_bm25negs)\n",
    "        if triple != 0:\n",
    "            max5_q2p_triples.append(triple)\n",
    "            total_triples += 1\n",
    "print(\"miss_hids = {:,}, triples with simnegs = {:,}, triples with complnegs = {:,}, triples with bm25negs = {:,}\".format(\n",
    "    len(miss_hids), len(hids_have_simnegs), len(hids_have_complnegs), len(hids_have_bm25negs)\n",
    "))\n",
    "print(\"total triples = {:,}\".format(total_triples))\n",
    "print(\"=\"*75)\n",
    "\n",
    "miss_hids, hids_have_simnegs, hids_have_complnegs, hids_have_bm25negs = [], [], [], []\n",
    "total_triples = 0   \n",
    "for qid, pos_pids in max2_q2p.items():\n",
    "    for pos_pid in pos_pids:\n",
    "        triple = create_mixture_triples_for_search(qid, pos_pid, \n",
    "                                                   hid_to_simpids_sampler=train_aid_to_simpids,\n",
    "                                                   hid_to_complpids_sampler=train_aid_to_complpids, \n",
    "                                                   bm25_hid_to_tid_sampler=bm25_hid_to_tids,\n",
    "                                                   miss_hids=miss_hids, \n",
    "                                                   hids_have_simnegs=hids_have_simnegs, \n",
    "                                                   hids_have_complnegs=hids_have_complnegs, \n",
    "                                                   hids_have_bm25negs=hids_have_bm25negs)\n",
    "        if triple != 0:\n",
    "            max2_q2p_triples.append(triple)\n",
    "            total_triples += 1\n",
    "print(\"miss_hids = {:,}, triples with simnegs = {:,}, triples with complnegs = {:,}, triples with bm25negs = {:,}\".format(\n",
    "    len(miss_hids), len(hids_have_simnegs), len(hids_have_complnegs), len(hids_have_bm25negs)\n",
    "))\n",
    "print(\"total triples = {:,}\".format(total_triples))\n",
    "print(\"=\"*75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c50a10-dc3f-468f-9c09-61b1378e1049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query oriented sampling max2, unique queries = 54,243, unique items = 101,144\n",
      "query oriented sampling max5, unique queries = 54,305, unique items = 226,267\n",
      "query oriented sampling max10, unique queries = 54,330, unique items = 386,333\n",
      "query oriented sampling max15, unique queries = 54,338, unique items = 491,241\n"
     ]
    }
   ],
   "source": [
    "#print(\"unique aids for simpids = {:,}, unique aids for complpids = {:,}\".format(len(max5_h2sp), len(max5_h2cp)))\n",
    "print(\"query oriented sampling max2, unique queries = {:,}, unique items = {:,}\".format(\n",
    "    len(set([q for (q, _, _) in max2_q2p_triples])), len(set([p for (_, p, _) in max2_q2p_triples]))))\n",
    "print(\"query oriented sampling max5, unique queries = {:,}, unique items = {:,}\".format(\n",
    "    len(set([q for (q, _, _) in max5_q2p_triples])), len(set([p for (_, p, _) in max5_q2p_triples]))))\n",
    "print(\"query oriented sampling max10, unique queries = {:,}, unique items = {:,}\".format(\n",
    "    len(set([q for (q, _, _) in max10_q2p_triples])), len(set([p for (_, p, _) in max10_q2p_triples]))))\n",
    "print(\"query oriented sampling max15, unique queries = {:,}, unique items = {:,}\".format(\n",
    "    len(set([q for (q, _, _) in max15_q2p_triples])), len(set([p for (_, p, _) in max15_q2p_triples]))))\n",
    "\n",
    "#print(\"h2sp triples = {:,}, h2cp triples = {:,}\".format(len(h2sp_triples), len(h2cp_triples)))\n",
    "#print(\"max2_q2p_triples = {:,}, max5_q2p _triples = {:,}, max10_q2p_triples = {:,}, max15_q2p_triples = {:,}\".format(\n",
    "#    len(max2_q2p_triples), len(max5_q2p_triples), len(max10_q2p_triples), len(max15_q2p_triples)\n",
    "#))total_triples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513ddd43-551d-451f-b6f1-a8aef7685b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "out_dir = os.path.join(in_dir, \"unified_train/\")\n",
    "if not os.path.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "\n",
    "fn_to_tripleNrel = {\n",
    "    \"max2_qorient_q2p.scbnegs.train.tsv\": (max2_q2p_triples, REL_RELATION),\n",
    "    \"max5_qorient_q2p.scbnegs.train.tsv\": (max5_q2p_triples, REL_RELATION),\n",
    "    \"max10_qorient_q2p.scbnegs.train.tsv\": (max10_q2p_triples, REL_RELATION),\n",
    "    \"max15_qorient_q2p.scbnegs.train.tsv\": (max15_q2p_triples, REL_RELATION),\n",
    "}\n",
    "\n",
    "for fn, (triples, relation) in fn_to_tripleNrel.items():\n",
    "    with open(os.path.join(out_dir, fn), \"w\") as fout:\n",
    "        for (hid, pos_tid, neg_tid) in triples:\n",
    "            fout.write(f\"{hid}\\t{pos_tid}\\t{neg_tid}\\t{relation}\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f765171-1c19-4e20-8883-a3c03a0d18f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600567 /home/jupyter/unity_jointly_rec_and_search/datasets/amazon_esci_dataset/task_2_multiclass_product_classification/unified_train/max15_qorient_q2p.scbnegs.train.tsv\n",
      "1267636\t517038\t515292\tis_relevant_to\n",
      "1267636\t1093650\t517038\tis_relevant_to\n",
      "1267636\t517040\t1141802\tis_relevant_to\n",
      "1267636\t517033\t777499\tis_relevant_to\n",
      "1267636\t517034\t90103\tis_relevant_to\n",
      "1281425\t973124\t1195268\tis_relevant_to\n",
      "1281425\t695445\t1195266\tis_relevant_to\n",
      "1281425\t971808\t1195242\tis_relevant_to\n",
      "1281425\t695448\t775789\tis_relevant_to\n",
      "1281425\t953046\t775794\tis_relevant_to\n",
      "====================================================================================================\n",
      "105906 /home/jupyter/unity_jointly_rec_and_search/datasets/amazon_esci_dataset/task_2_multiclass_product_classification/unified_train/max2_qorient_q2p.scbnegs.train.tsv\n",
      "1267636\t517030\t515433\tis_relevant_to\n",
      "1267636\t517039\t428761\tis_relevant_to\n",
      "1228232\t116172\t116161\tis_relevant_to\n",
      "1228232\t116163\t856362\tis_relevant_to\n",
      "1275084\t600152\t489173\tis_relevant_to\n",
      "1279154\t651903\t997221\tis_relevant_to\n",
      "1224704\t82034\t661050\tis_relevant_to\n",
      "1224704\t82036\t5376\tis_relevant_to\n",
      "1281425\t1195273\t187194\tis_relevant_to\n",
      "1281425\t695448\t762340\tis_relevant_to\n",
      "====================================================================================================\n",
      "249381 /home/jupyter/unity_jointly_rec_and_search/datasets/amazon_esci_dataset/task_2_multiclass_product_classification/unified_train/max5_qorient_q2p.scbnegs.train.tsv\n",
      "1267636\t517033\t453383\tis_relevant_to\n",
      "1267636\t892198\t515292\tis_relevant_to\n",
      "1267636\t517035\t758065\tis_relevant_to\n",
      "1267636\t517038\t515292\tis_relevant_to\n",
      "1267636\t517037\t515292\tis_relevant_to\n",
      "1281425\t1195273\t695447\tis_relevant_to\n",
      "1281425\t775780\t762340\tis_relevant_to\n",
      "1281425\t953046\t1195259\tis_relevant_to\n",
      "1281425\t695443\t1195250\tis_relevant_to\n",
      "1281425\t971808\t762336\tis_relevant_to\n",
      "====================================================================================================\n",
      "452082 /home/jupyter/unity_jointly_rec_and_search/datasets/amazon_esci_dataset/task_2_multiclass_product_classification/unified_train/max10_qorient_q2p.scbnegs.train.tsv\n",
      "1267636\t517034\t892201\tis_relevant_to\n",
      "1267636\t517035\t943534\tis_relevant_to\n",
      "1267636\t517036\t224234\tis_relevant_to\n",
      "1267636\t1093650\t603545\tis_relevant_to\n",
      "1267636\t892202\t515292\tis_relevant_to\n",
      "1281425\t953046\t1196298\tis_relevant_to\n",
      "1281425\t695443\t1195247\tis_relevant_to\n",
      "1281425\t973124\t762341\tis_relevant_to\n",
      "1281425\t695445\t973116\tis_relevant_to\n",
      "1281425\t971808\t187235\tis_relevant_to\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "in_dir=\"/home/jupyter/unity_jointly_rec_and_search/datasets/amazon_esci_dataset/task_2_multiclass_product_classification/\"\n",
    "out_dir = os.path.join(in_dir, \"unified_train/\")\n",
    "for path in os.listdir(out_dir):\n",
    "    if not path.endswith(\"scbnegs.train.tsv\"):\n",
    "        continue\n",
    "    path = os.path.join(out_dir, path)\n",
    "    ! wc -l $path\n",
    "    ! head -n 5 $path\n",
    "    ! tail -n 5 $path\n",
    "    print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ece00e61-565c-4afc-a69b-6ee77029422c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blonde wig bob\n",
      "QDBOWIN QUEEN HAIR Brown Rooted Honey Blonde Ombre Lace Front Wigs for Women Flawless Wavy Bob Hair Heat Resistant Synthetic Wig Half Hand Tied 14 inch\n",
      "Highlight Straight Bob Wigs Honey Blonde Ombre Short Wigs with Bangs 4/27 Mix Brown Color Unprocessed Brazilian Virgin Hair for Black Women Non Lace Front Human Hair (12 Inch)\n"
     ]
    }
   ],
   "source": [
    "hid, pos_tid, neg_tid = (1224704,82036,5376)\n",
    "print(eid_to_text[hid])\n",
    "print(eid_to_text[pos_tid])\n",
    "print(eid_to_text[neg_tid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad2f26e-dd21-40de-be2a-3dbef8ea321f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
