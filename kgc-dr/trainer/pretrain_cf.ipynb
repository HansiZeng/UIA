{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e37a4263-77fd-4249-9645-e72b4c9af754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users, items = 893619.000, 2260878.000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from scipy import sparse as sp\n",
    "\n",
    "data_dir = \"/home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/\"\n",
    "\n",
    "search_path = os.path.join(data_dir, \"train_searchs.csv\")\n",
    "sim_rec_path = os.path.join(data_dir, \"train_sim_recs.csv\") \n",
    "compl_rec_path = os.path.join(data_dir, \"train_compl_recs.csv\") \n",
    "\n",
    "sim_rec_df = pd.read_csv(sim_rec_path, index_col=0)\n",
    "compl_rec_df = pd.read_csv(compl_rec_path, index_col=0)\n",
    "search_df = pd.read_csv(search_path, index_col=0)\n",
    "\n",
    "with open(os.path.join(data_dir, \"user_to_uid.pkl\"), \"rb\") as fin:\n",
    "    user_to_uid = pkl.load(fin)\n",
    "with open(os.path.join(data_dir, \"ivm_to_pid.pkl\"), \"rb\") as fin:\n",
    "    ivm_to_pid = pkl.load(fin)\n",
    "    \n",
    "print(\"number of users, items = {:,}, {:,}\".format(len(user_to_uid), len(ivm_to_pid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "186f0465-9974-45d2-bfe2-d8309e89f448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uids, aids, sim_pids densities = 8.813, 7.352, 10.097\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse as sp\n",
    "\n",
    "#sim_rec_df[\"sim_pids\"] = sim_rec_df[\"sim_pids\"].apply(lambda x: eval(x))\n",
    "sim_rec_df = sim_rec_df.explode(\"sim_pids\")\n",
    "sim_rec_df[\"sim_pids\"] = sim_rec_df[\"sim_pids\"].astype(\"int64\")\n",
    "sim_rec_df = sim_rec_df.drop_duplicates([\"uid\", \"aid\", \"sim_pids\"])\n",
    "\n",
    "uids, aids, sim_pids = np.array(sim_rec_df.uid), np.array(sim_rec_df.aid), np.array(sim_rec_df.sim_pids)\n",
    "assert len(uids) == len(aids) == len(sim_pids)\n",
    "assert type(uids[0]) == type(aids[0]) == type(sim_pids[0])\n",
    "print(\"uids, aids, sim_pids densities = {:.3f}, {:.3f}, {:.3f}\".format(\n",
    "    len(uids) / len(np.unique(uids)), len(aids) / len(np.unique(aids)), len(sim_pids) / len(np.unique(sim_pids))\n",
    "))\n",
    "\n",
    "targets = np.ones(len(uids))\n",
    "ui_shape = (len(user_to_uid), len(ivm_to_pid))\n",
    "ai_shape = (len(ivm_to_pid), len(ivm_to_pid))\n",
    "\n",
    "ui_data = sp.coo_matrix((targets, (uids, sim_pids)), shape=ui_shape).tocsr()\n",
    "ai_data = sp.coo_matrix((targets, (aids, sim_pids)), shape=ai_shape).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f3598fe1-c5f8-437a-893f-e2405d1568d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd967a1ab99e45d399715988b415c588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70d7f9719bbb40f4b68c1cd6bb466d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import implicit\n",
    "\n",
    "ui_model = implicit.als.AlternatingLeastSquares(factors=100, use_gpu=False)\n",
    "ai_model = implicit.als.AlternatingLeastSquares(factors=100, use_gpu=False)\n",
    "\n",
    "ui_model.fit(ui_data)\n",
    "ai_model.fit(ai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c51318a8-360b-4c9b-b4db-8af6d6064b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109379/109379 [00:06<00:00, 16145.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 0.025078369905956112\n",
      "4096 0.050156739811912224\n",
      "6144 0.07523510971786834\n",
      "8192 0.10031347962382445\n",
      "10240 0.12539184952978055\n",
      "12288 0.15047021943573669\n",
      "14336 0.1755485893416928\n",
      "16384 0.2006269592476489\n",
      "18432 0.22570532915360503\n",
      "20480 0.2507836990595611\n",
      "22528 0.27586206896551724\n",
      "24576 0.30094043887147337\n",
      "26624 0.32601880877742945\n",
      "28672 0.3510971786833856\n",
      "30720 0.3761755485893417\n",
      "43008 0.5266457680250783\n",
      "45056 0.5517241379310345\n",
      "47104 0.5768025078369906\n",
      "49152 0.6018808777429467\n",
      "51200 0.6269592476489029\n",
      "53248 0.6520376175548589\n",
      "55296 0.677115987460815\n",
      "57344 0.7021943573667712\n",
      "59392 0.7272727272727273\n",
      "61440 0.7523510971786834\n",
      "63488 0.7774294670846394\n",
      "65536 0.8025078369905956\n",
      "67584 0.8275862068965517\n",
      "69632 0.8526645768025078\n",
      "71680 0.877742946708464\n",
      "73728 0.9028213166144201\n",
      "75776 0.9278996865203761\n",
      "77824 0.9529780564263323\n",
      "79872 0.9780564263322884\n",
      "81664 1.0\n",
      "2048 0.05029716587258706\n",
      "4096 0.10059433174517413\n",
      "6144 0.1508914976177612\n",
      "8192 0.20118866349034825\n",
      "10240 0.2514858293629353\n",
      "12288 0.3017829952355224\n",
      "14336 0.3520801611081094\n",
      "16384 0.4023773269806965\n",
      "18432 0.45267449285328354\n",
      "20480 0.5029716587258706\n",
      "22528 0.5532688245984577\n",
      "24576 0.6035659904710448\n",
      "26624 0.6538631563436318\n",
      "28672 0.7041603222162188\n",
      "30720 0.754457488088806\n",
      "32768 0.804754653961393\n",
      "34816 0.85505181983398\n",
      "36864 0.9053489857065671\n",
      "38912 0.9556461515791542\n",
      "40718 1.0\n"
     ]
    }
   ],
   "source": [
    "test_sim_rec_df = pd.read_csv(os.path.join(data_dir, \"test_sim_recs.csv\"), index_col=0)\n",
    "test_sim_rec_df[\"sim_pids\"] = test_sim_rec_df[\"sim_pids\"].apply(lambda x: eval(x))\n",
    "test_sim_rec_df = test_sim_rec_df.explode(\"sim_pids\")\n",
    "test_sim_rec_df[\"sim_pids\"] = test_sim_rec_df[\"sim_pids\"].astype(\"int64\")\n",
    "test_sim_rec_df = test_sim_rec_df.drop_duplicates([\"uid\", \"aid\", \"sim_pids\"])\n",
    "\n",
    "test_ui_reldata = {}\n",
    "test_ai_reldata = {}\n",
    "for i, row in tqdm(test_sim_rec_df.iterrows(), total=len(test_sim_rec_df)):\n",
    "    uid, aid, simpid = row.uid, row.aid, row.sim_pids\n",
    "    if uid not in test_ui_reldata:\n",
    "        test_ui_reldata[uid] = {}\n",
    "        test_ui_reldata[uid][simpid] = 1.\n",
    "    else:\n",
    "        test_ui_reldata[uid][simpid] = 1.\n",
    "    if aid not in test_ai_reldata:\n",
    "        test_ai_reldata[aid] = {}\n",
    "        test_ai_reldata[aid][simpid] = 1.\n",
    "    else:\n",
    "        test_ai_reldata[aid][simpid] = 1.\n",
    "            \n",
    "test_uids = np.array(test_sim_rec_df.uid.unique())\n",
    "test_aids = np.array(test_sim_rec_df.aid.unique())\n",
    "\n",
    "def get_ranking(model, uids, batch_size=2048, topk=1000):\n",
    "    uid_to_ranklist = {}\n",
    "    start_idx = 0\n",
    "    while start_idx < len(uids):\n",
    "        end_idx = min(len(uids), start_idx+batch_size)\n",
    "        batch_uids = uids[start_idx: end_idx]\n",
    "        score = -model.user_factors[batch_uids] @ model.item_factors.T # [bz, num_items]\n",
    "        top_indices = np.argpartition(score, topk, axis=-1)\n",
    "        batch_top_pids = top_indices[:, :topk]\n",
    "        #top_pids = top_indices[score[top_indices].argsort()]\n",
    "        \n",
    "        for i, (uid, top_pids) in enumerate(zip(batch_uids, batch_top_pids)):\n",
    "            assert len(top_pids) == topk\n",
    "            uid_to_ranklist[uid] = top_pids[score[i][top_pids].argsort()]\n",
    "        \n",
    "        start_idx = end_idx\n",
    "        print(start_idx, start_idx / len(uids))\n",
    "            \n",
    "    return uid_to_ranklist\n",
    "\n",
    "uid_to_ranklist = get_ranking(ui_model, test_uids)\n",
    "aid_to_ranklist = get_ranking(ai_model, test_aids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84523ac9-8235-4fde-bbfb-faa20aed01a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "def _calculate_metrics_plain(ranking, qrels,binarization_point=1.0,return_per_query=False):\n",
    "    '''\n",
    "    calculate main evaluation metrics for the given results (without looking at candidates),\n",
    "    returns a dict of metrics\n",
    "    '''\n",
    "\n",
    "    ranked_queries = len(ranking)\n",
    "\n",
    "    qidx_to_qid = {idx:qid for idx, qid in enumerate(ranking)}\n",
    "\n",
    "    rr_per_candidate_depth = np.zeros((2,ranked_queries))\n",
    "    rank_per_candidate_depth = np.zeros((2,ranked_queries))\n",
    "    recall_per_candidate_depth = np.zeros((2,ranked_queries))\n",
    "    ndcg_per_candidate_depth = np.zeros((2,ranked_queries))\n",
    "    ap_per_candidate_depth = np.zeros((ranked_queries))\n",
    "    evaluated_queries = 0\n",
    "\n",
    "    for query_index,(query_id,ranked_doc_ids) in enumerate(ranking.items()):\n",
    "        if query_id in qrels:\n",
    "            evaluated_queries += 1\n",
    "\n",
    "            relevant_ids = np.array(list(qrels[query_id].keys())) # key, value guaranteed in same order\n",
    "            relevant_grades = np.array(list(qrels[query_id].values()))\n",
    "            sorted_relevant_grades = np.sort(relevant_grades)[::-1]\n",
    "\n",
    "            num_relevant = relevant_ids.shape[0]\n",
    "            np_rank = np.array(ranked_doc_ids)\n",
    "            relevant_mask = np.in1d(np_rank,relevant_ids) # shape: (ranking_depth,) - type: bool\n",
    "\n",
    "            binary_relevant = relevant_ids[relevant_grades >= binarization_point]\n",
    "            binary_num_relevant = binary_relevant.shape[0]\n",
    "            binary_relevant_mask = np.in1d(np_rank,binary_relevant) # shape: (ranking_depth,) - type: bool\n",
    "\n",
    "            # check if we have a relevant document at all in the results -> if not skip and leave 0 \n",
    "            if np.any(binary_relevant_mask):\n",
    "\n",
    "                # now select the relevant ranks across the fixed ranks\n",
    "                ranks = np.arange(1,binary_relevant_mask.shape[0]+1)[binary_relevant_mask]\n",
    "\n",
    "                #\n",
    "                # ap\n",
    "                #\n",
    "                map_ranks = ranks[ranks <= 1000]\n",
    "                ap = np.arange(1,map_ranks.shape[0]+1) / map_ranks\n",
    "                ap = np.sum(ap) / binary_num_relevant\n",
    "                ap_per_candidate_depth[query_index] = ap\n",
    "\n",
    "                # mrr only the first relevant rank is used\n",
    "                first_rank = ranks[0]\n",
    "\n",
    "                for cut_indx, cutoff in enumerate([10, 1000]):\n",
    "\n",
    "                    curr_ranks = ranks.copy()\n",
    "                    curr_ranks[curr_ranks > cutoff] = 0 \n",
    "                    #\n",
    "                    # mrr\n",
    "                    #\n",
    "\n",
    "                    # ignore ranks that are out of the interest area (leave 0)\n",
    "                    if first_rank <= cutoff: \n",
    "                        rr_per_candidate_depth[cut_indx,query_index] = 1 / first_rank\n",
    "                        rank_per_candidate_depth[cut_indx,query_index] = first_rank\n",
    "\n",
    "                for cut_idx, cutoff in enumerate([10,1000]):\n",
    "                    curr_ranks = ranks.copy()\n",
    "                    curr_ranks[curr_ranks > cutoff] = 0 \n",
    "                    recall = (curr_ranks > 0).sum(axis=0) / binary_num_relevant\n",
    "                    recall_per_candidate_depth[cut_idx,query_index] = recall\n",
    "\n",
    "            if np.any(relevant_mask):\n",
    "\n",
    "                # now select the relevant ranks across the fixed ranks\n",
    "                ranks = np.arange(1,relevant_mask.shape[0]+1)[relevant_mask]\n",
    "\n",
    "                grades_per_rank = np.ndarray(ranks.shape[0],dtype=int)\n",
    "                for i,id in enumerate(np_rank[relevant_mask]):\n",
    "                    grades_per_rank[i]=np.where(relevant_ids==id)[0]\n",
    "\n",
    "                grades_per_rank = relevant_grades[grades_per_rank]\n",
    "\n",
    "                #\n",
    "                # ndcg = dcg / idcg \n",
    "                #\n",
    "                for cut_indx, cutoff in enumerate([10,1000]):\n",
    "                    #\n",
    "                    # get idcg (from relevant_ids)\n",
    "                    idcg = (sorted_relevant_grades[:cutoff] / np.log2(1 + np.arange(1,min(num_relevant,cutoff) + 1)))\n",
    "\n",
    "                    curr_ranks = ranks.copy()\n",
    "                    curr_ranks[curr_ranks > cutoff] = 0 \n",
    "\n",
    "                    #coverage_per_candidate_depth[cut_indx, query_index] = (curr_ranks > 0).sum() / float(cutoff)\n",
    "\n",
    "                    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                        c = np.true_divide(grades_per_rank,np.log2(1 + curr_ranks))\n",
    "                        c[c == np.inf] = 0\n",
    "                        dcg = np.nan_to_num(c)\n",
    "\n",
    "                    nDCG = dcg.sum(axis=-1) / idcg.sum()\n",
    "\n",
    "                    ndcg_per_candidate_depth[cut_indx,query_index] = nDCG\n",
    "\n",
    "    #avg_coverage = coverage_per_candidate_depth.sum(axis=-1) / evaluated_queries\n",
    "    mrr = rr_per_candidate_depth.sum(axis=-1) / evaluated_queries\n",
    "    relevant = (rr_per_candidate_depth > 0).sum(axis=-1)\n",
    "    non_relevant = (rr_per_candidate_depth == 0).sum(axis=-1)\n",
    "\n",
    "    \"\"\"\n",
    "    avg_rank=np.apply_along_axis(lambda v: np.mean(v[np.nonzero(v)]), -1, rank_per_candidate_depth)\n",
    "    avg_rank[np.isnan(avg_rank)]=0.\n",
    "\n",
    "    median_rank=np.apply_along_axis(lambda v: np.median(v[np.nonzero(v)]), -1, rank_per_candidate_depth)\n",
    "    median_rank[np.isnan(median_rank)]=0.\n",
    "    \"\"\"\n",
    "    map_score = ap_per_candidate_depth.sum(axis=-1) / evaluated_queries\n",
    "    recall = recall_per_candidate_depth.sum(axis=-1) / evaluated_queries\n",
    "    nDCG = ndcg_per_candidate_depth.sum(axis=-1) / evaluated_queries\n",
    "\n",
    "    local_dict={}\n",
    "\n",
    "    for cut_indx, cutoff in enumerate([10,1000]):\n",
    "\n",
    "        local_dict['MRR@'+str(cutoff)] = mrr[cut_indx]\n",
    "        #local_dict['QueriesWithNoRelevant@'+str(cutoff)] = non_relevant[cut_indx]\n",
    "        local_dict['QueriesWithRelevant@'+str(cutoff)] = relevant[cut_indx]\n",
    "        #local_dict['AverageRankGoldLabel@'+str(cutoff)] = avg_rank[cut_indx]\n",
    "        #local_dict['MedianRankGoldLabel@'+str(cutoff)] = median_rank[cut_indx]\n",
    "\n",
    "    for cut_indx, cutoff in enumerate([10,1000]):\n",
    "        local_dict['Recall@'+str(cutoff)] = recall[cut_indx]\n",
    "\n",
    "    for cut_indx, cutoff in enumerate([10,1000]):\n",
    "        #local_dict['Avg_coverage@'+str(cutoff)] = avg_coverage[cut_indx]\n",
    "        local_dict['nDCG@'+str(cutoff)] = nDCG[cut_indx]\n",
    "\n",
    "    local_dict[\"MAP@\"+str(1000)] = map_score\n",
    "\n",
    "    local_dict['QueriesRanked'] = evaluated_queries\n",
    "\n",
    "    if return_per_query:\n",
    "        return local_dict,rr_per_candidate_depth,recall_per_candidate_depth,ndcg_per_candidate_depth, qidx_to_qid, qrels\n",
    "    else:\n",
    "        return local_dict\n",
    "        \n",
    "ui_result = _calculate_metrics_plain(uid_to_ranklist, test_ui_reldata)\n",
    "ai_result = _calculate_metrics_plain(aid_to_ranklist, test_ai_reldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bdfde62-82a1-4431-983a-3cac47a28c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'MRR@10': 0.12848136732161516,\n",
       "  'QueriesWithRelevant@10': 19666,\n",
       "  'MRR@1000': 0.13421565944717023,\n",
       "  'QueriesWithRelevant@1000': 43670,\n",
       "  'Recall@10': 0.2148971226235994,\n",
       "  'Recall@1000': 0.5136589299708912,\n",
       "  'nDCG@10': 0.14111959727735726,\n",
       "  'nDCG@1000': 0.19248874069304256,\n",
       "  'MAP@1000': 0.11840409862342591,\n",
       "  'QueriesRanked': 81664},\n",
       " {'MRR@10': 0.1465949792494564,\n",
       "  'QueriesWithRelevant@10': 9988,\n",
       "  'MRR@1000': 0.15065814610725997,\n",
       "  'QueriesWithRelevant@1000': 15242,\n",
       "  'Recall@10': 0.170981202532537,\n",
       "  'Recall@1000': 0.35062336823934886,\n",
       "  'nDCG@10': 0.12993301089907136,\n",
       "  'nDCG@1000': 0.17442168253031834,\n",
       "  'MAP@1000': 0.10880731329619221,\n",
       "  'QueriesRanked': 40718})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_result, ai_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4314cf-5114-4d96-a76e-dc57e5540c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
