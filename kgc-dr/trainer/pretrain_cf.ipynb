{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37a4263-77fd-4249-9645-e72b4c9af754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/lib/arraysetops.py:580: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask |= (ar1 == a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users, items = 893,619, 2,260,878\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from scipy import sparse as sp\n",
    "\n",
    "data_dir = \"/home/jupyter/unity_jointly_rec_and_search/datasets/unified_user/\"\n",
    "\n",
    "search_path = os.path.join(data_dir, \"train_searchs.csv\")\n",
    "sim_rec_path = os.path.join(data_dir, \"train_sim_recs.csv\") \n",
    "compl_rec_path = os.path.join(data_dir, \"train_compl_recs.csv\") \n",
    "\n",
    "sim_rec_df = pd.read_csv(sim_rec_path, index_col=0)\n",
    "compl_rec_df = pd.read_csv(compl_rec_path, index_col=0)\n",
    "search_df = pd.read_csv(search_path, index_col=0)\n",
    "\n",
    "with open(os.path.join(data_dir, \"user_to_uid.pkl\"), \"rb\") as fin:\n",
    "    user_to_uid = pkl.load(fin)\n",
    "with open(os.path.join(data_dir, \"ivm_to_pid.pkl\"), \"rb\") as fin:\n",
    "    ivm_to_pid = pkl.load(fin)\n",
    "    \n",
    "print(\"number of users, items = {:,}, {:,}\".format(len(user_to_uid), len(ivm_to_pid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "186f0465-9974-45d2-bfe2-d8309e89f448",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "eval() arg 1 must be a string, bytes or code object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15822/3737215588.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msim_rec_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sim_pids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_rec_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sim_pids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msim_rec_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_rec_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sim_pids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msim_rec_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sim_pids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_rec_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sim_pids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                     \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15822/3737215588.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msim_rec_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sim_pids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_rec_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sim_pids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msim_rec_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_rec_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sim_pids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msim_rec_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sim_pids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim_rec_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sim_pids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: eval() arg 1 must be a string, bytes or code object"
     ]
    }
   ],
   "source": [
    "from scipy import sparse as sp\n",
    "\n",
    "sim_rec_df[\"sim_pids\"] = sim_rec_df[\"sim_pids\"].apply(lambda x: eval(x))\n",
    "sim_rec_df = sim_rec_df.explode(\"sim_pids\")\n",
    "sim_rec_df[\"sim_pids\"] = sim_rec_df[\"sim_pids\"].astype(\"int64\")\n",
    "sim_rec_df = sim_rec_df.drop_duplicates([\"uid\", \"aid\", \"sim_pids\"])\n",
    "\n",
    "compl_rec_df[\"compl_pids\"] = compl_rec_df[\"compl_pids\"].apply(lambda x: eval(x))\n",
    "compl_rec_df = compl_rec_df.explode(\"compl_pids\")\n",
    "compl_rec_df[\"compl_pids\"] = compl_rec_df[\"compl_pids\"].astype(\"int64\")\n",
    "compl_rec_df = compl_rec_df.drop_duplicates([\"uid\", \"aid\", \"compl_pids\"])\n",
    "\n",
    "search_df[\"rel_pids\"] = search_df[\"rel_pids\"].apply(lambda x: eval(x))\n",
    "search_df = search_df.explode(\"rel_pids\")\n",
    "search_df[\"rel_pids\"] = search_df[\"rel_pids\"].astype(\"int64\")\n",
    "search_df = search_df.drop_duplicates([\"uid\", \"qid\", \"rel_pids\"])\n",
    "\n",
    "#uids, aids, sim_pids = np.array(sim_rec_df.uid), np.array(sim_rec_df.aid), np.array(sim_rec_df.sim_pids)\n",
    "#assert len(uids) == len(aids) == len(sim_pids)\n",
    "#assert type(uids[0]) == type(aids[0]) == type(sim_pids[0])\n",
    "#print(\"uids, aids, sim_pids densities = {:.3f}, {:.3f}, {:.3f}\".format(\n",
    "#    len(uids) / len(np.unique(uids)), len(aids) / len(np.unique(aids)), len(sim_pids) / len(np.unique(sim_pids))\n",
    "#))\n",
    "\n",
    "#targets = np.ones(len(uids))\n",
    "#ui_shape = (len(user_to_uid), len(ivm_to_pid))\n",
    "#ai_shape = (len(ivm_to_pid), len(ivm_to_pid))\n",
    "\n",
    "#ui_data = sp.coo_matrix((targets, (uids, sim_pids)), shape=ui_shape).tocsr()\n",
    "#ai_data = sp.coo_matrix((targets, (aids, sim_pids)), shape=ai_shape).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0d7e514-727b-416b-82b4-cf62a95a46eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_RELATION = \"is_similar_to\"\n",
    "COMPL_RELATION = \"is_complementary_to\"\n",
    "REL_RELATION = \"is_relevant_to\"\n",
    "\n",
    "sim_rec_df[\"relation\"] = SIM_RELATION\n",
    "compl_rec_df[\"relation\"] = COMPL_RELATION\n",
    "search_df[\"relation\"] = REL_RELATION\n",
    "sim_rec_df.rename({\"sim_pids\": \"pid\"}, axis=1, inplace=True)\n",
    "compl_rec_df.rename({\"compl_pids\": \"pid\"}, axis=1, inplace=True)\n",
    "search_df.rename({\"rel_pids\": \"pid\"}, axis=1, inplace=True)\n",
    "\n",
    "merge_df = pd.concat([\n",
    "    sim_rec_df[[\"uid\", \"pid\", \"relation\"]],\n",
    "    compl_rec_df[[\"uid\", \"pid\", \"relation\"]],\n",
    "    search_df[[\"uid\", \"pid\", \"relation\"]]\n",
    "])\n",
    "\n",
    "REL_TO_ID = {\n",
    "    SIM_RELATION: 0,\n",
    "    COMPL_RELATION: 1,\n",
    "    REL_RELATION: 2\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0869811e-d00a-40a9-a633-3b720cac43bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uids': tensor([879029, 588698, 710444, 721113, 142077, 566914, 428127, 308658,  67313,\n",
      "         13947, 328308, 412394, 273223, 797188, 831989, 509147, 497062, 354090,\n",
      "        213729, 628916, 796984, 652821, 247175, 218926,   3382, 238957, 203408,\n",
      "        190488,  40832, 170600, 717995, 357042, 173007, 819296, 252563, 807093,\n",
      "        484226,   4861, 861254, 792930, 778791, 250004,  94299, 817511, 416668,\n",
      "        787394, 819172,  10723, 460068, 170547, 522535, 560899,  67905,  92333,\n",
      "         88598, 498621, 560310, 348197, 708012, 787196, 313623, 712585, 405548,\n",
      "        733181, 594586, 228395, 595665, 255407, 878264, 572620, 811249, 127682,\n",
      "          6460, 226774,  11796, 786224, 776052,  38506, 633519, 514078, 333475,\n",
      "        496229, 158783, 350328, 450630,  29206, 608013,  87755, 393672,  66659,\n",
      "        791344, 452087, 882379, 687447, 131698, 573455, 354961, 585695, 406704,\n",
      "        569486, 578371, 807503,  87980, 233230, 533432, 729124, 107085, 417206,\n",
      "         96554, 169045, 779354, 590818, 862989, 681746,  95915, 808827, 698544,\n",
      "        529870, 238424, 481137, 191330,   6746, 755897, 771783, 260284, 131108,\n",
      "        346161, 620139]), 'pids': tensor([ 420499,  467615, 2024882, 1365056, 2185938,  896194,  259075,  290365,\n",
      "         613437,  721562, 2002878,  319262, 1129701, 1160456, 1880383, 1360519,\n",
      "        1947892, 2164024,  779829,  499503, 2166611, 1053790,  326280, 1842838,\n",
      "         228284,  282126, 2059877,  613576, 1505423, 1898065, 1177190, 1583067,\n",
      "        1837108, 1909920,   84957,  162551, 1360331, 1577977, 1993659, 1398108,\n",
      "         275440, 1819136,  545636, 1013357,  998413,  312001,  247290,  471538,\n",
      "        1103758, 1273064, 1006478, 2070899, 1322555,  936556,   87754,  664654,\n",
      "         162518,  316691,  574485, 1563138, 1419181, 1565696, 1251537, 1186717,\n",
      "        1239278, 1494144, 1685641,   28713, 2133804,  215298, 1844754, 1486839,\n",
      "         415069,  571966, 1106573, 1258448,  659045, 1430221, 1206143, 1574008,\n",
      "        1672911, 2193135,  622050, 1013737,  208635, 1124158,  871048,  169082,\n",
      "        1359892,  708927,  851148, 1139623, 2121216,   14217, 2028665,  793572,\n",
      "        1744460,  543452, 1274579, 1109451, 2057372, 1282020,  499606,  689249,\n",
      "         140957,  998368, 1897165,  243568, 1115419,  559140,  320969,  899379,\n",
      "         684653, 1757762, 1476685, 2189763,   69951, 1077739,  694174,  172405,\n",
      "         172405, 1813648,  402398, 1755691,  368062, 1894637, 1639928,  931343]), 'rel_ids': tensor([2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 0,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2])}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from utils import  AverageMeter\n",
    "\n",
    "class CFDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return list(self.df.iloc[idx])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def collate_fn(self, batch):\n",
    "        uids, pids, rel_ids = [], [], []\n",
    "        for uid, pid, rel in batch:\n",
    "            uids.append(uid)\n",
    "            pids.append(pid)\n",
    "            rel_ids.append(REL_TO_ID[rel])\n",
    "            \n",
    "        return {\n",
    "            \"user_ids\": torch.LongTensor(uids),\n",
    "            \"item_ids\": torch.LongTensor(pids),\n",
    "            \"rel_ids\": torch.LongTensor(rel_ids),\n",
    "        }\n",
    "    \n",
    "class CF(torch.nn.Module):\n",
    "    def __init__(self, ui_emb_size, rel_emb_size, num_user, num_item, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.user_embs = nn.Embedding(num_user, ui_emb_size)\n",
    "        self.item_embs = nn.Embedding(num_item, ui_emb_size)\n",
    "        self.rel_embs = nn.Embedding(len(REL_TO_ID), rel_emb_size)\n",
    "        \n",
    "        self.dense = nn.Sequential(\n",
    "                        nn.Linear(ui_emb_size+rel_emb_size, ui_emb_size),\n",
    "                        nn.Dropout(p=dropout_rate),\n",
    "                        nn.ReLU()\n",
    "                    )\n",
    "        \n",
    "        self.loss = ContrastiveLoss()\n",
    "        \n",
    "    def forward(self, user_ids, item_ids, rel_ids):\n",
    "        user_embs = self.query_embs(user_ids, rel_ids)\n",
    "        item_embs = self.passage_embs(item_ids)\n",
    "        \n",
    "        return self.loss(user_embs, item_embs)\n",
    "        \n",
    "    def query_embs(self, user_ids, rel_ids):\n",
    "        hidden_states = torch.cat([self.user_embs[user_ids], self.item_embs[item_ids]], dim=-1)\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        return hidden_states\n",
    "    \n",
    "    def passage_embs(self, item_ids):\n",
    "        return self.item_embs(item_ids)\n",
    "\n",
    "class ContrastiveLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def __call__(self, user_embs, item_embs):\n",
    "        logits = user_embs @ item_embs\n",
    "        targets = torch.arange(len(user_embs), dtype=torch.long).to(device=logits.device)\n",
    "        \n",
    "        return self.loss_fn(logits, targets)\n",
    "    \n",
    "def train(model, train_dataloader):\n",
    "    loss_avg_meter = AverageMeter()\n",
    "    global_step = 1\n",
    "    print(\"batch: {}, step: {}, loss: {}\")\n",
    "    for epoch in range(128):\n",
    "        for batch in train_dataloader:\n",
    "            loss = model(**batch)\n",
    "            loss_avg_meter.update(loss.item())\n",
    "        \n",
    "        if (global_step+1) % 4_000 == 0:\n",
    "            print(f\"{batch} {global_step} {loss_avg_meter.avg:.3f}\")\n",
    "            loss_avg_meter.reset()\n",
    "            \n",
    "        global_step += 1\n",
    "\n",
    "train_dataset = CFDataset(merge_df)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, num_workers=4, shuffle=True, batch_size=128, \n",
    "                                              collate_fn=train_dataset.collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3598fe1-c5f8-437a-893f-e2405d1568d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ui_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15822/3361777459.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mai_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimplicit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlternatingLeastSquares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mui_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mui_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mai_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mai_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ui_data' is not defined"
     ]
    }
   ],
   "source": [
    "import implicit\n",
    "\n",
    "ui_model = implicit.als.AlternatingLeastSquares(factors=100, use_gpu=False)\n",
    "ai_model = implicit.als.AlternatingLeastSquares(factors=100, use_gpu=False)\n",
    "\n",
    "ui_model.fit(ui_data)\n",
    "ai_model.fit(ai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c51318a8-360b-4c9b-b4db-8af6d6064b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 109379/109379 [00:06<00:00, 16145.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 0.025078369905956112\n",
      "4096 0.050156739811912224\n",
      "6144 0.07523510971786834\n",
      "8192 0.10031347962382445\n",
      "10240 0.12539184952978055\n",
      "12288 0.15047021943573669\n",
      "14336 0.1755485893416928\n",
      "16384 0.2006269592476489\n",
      "18432 0.22570532915360503\n",
      "20480 0.2507836990595611\n",
      "22528 0.27586206896551724\n",
      "24576 0.30094043887147337\n",
      "26624 0.32601880877742945\n",
      "28672 0.3510971786833856\n",
      "30720 0.3761755485893417\n",
      "43008 0.5266457680250783\n",
      "45056 0.5517241379310345\n",
      "47104 0.5768025078369906\n",
      "49152 0.6018808777429467\n",
      "51200 0.6269592476489029\n",
      "53248 0.6520376175548589\n",
      "55296 0.677115987460815\n",
      "57344 0.7021943573667712\n",
      "59392 0.7272727272727273\n",
      "61440 0.7523510971786834\n",
      "63488 0.7774294670846394\n",
      "65536 0.8025078369905956\n",
      "67584 0.8275862068965517\n",
      "69632 0.8526645768025078\n",
      "71680 0.877742946708464\n",
      "73728 0.9028213166144201\n",
      "75776 0.9278996865203761\n",
      "77824 0.9529780564263323\n",
      "79872 0.9780564263322884\n",
      "81664 1.0\n",
      "2048 0.05029716587258706\n",
      "4096 0.10059433174517413\n",
      "6144 0.1508914976177612\n",
      "8192 0.20118866349034825\n",
      "10240 0.2514858293629353\n",
      "12288 0.3017829952355224\n",
      "14336 0.3520801611081094\n",
      "16384 0.4023773269806965\n",
      "18432 0.45267449285328354\n",
      "20480 0.5029716587258706\n",
      "22528 0.5532688245984577\n",
      "24576 0.6035659904710448\n",
      "26624 0.6538631563436318\n",
      "28672 0.7041603222162188\n",
      "30720 0.754457488088806\n",
      "32768 0.804754653961393\n",
      "34816 0.85505181983398\n",
      "36864 0.9053489857065671\n",
      "38912 0.9556461515791542\n",
      "40718 1.0\n"
     ]
    }
   ],
   "source": [
    "test_sim_rec_df = pd.read_csv(os.path.join(data_dir, \"test_sim_recs.csv\"), index_col=0)\n",
    "test_sim_rec_df[\"sim_pids\"] = test_sim_rec_df[\"sim_pids\"].apply(lambda x: eval(x))\n",
    "test_sim_rec_df = test_sim_rec_df.explode(\"sim_pids\")\n",
    "test_sim_rec_df[\"sim_pids\"] = test_sim_rec_df[\"sim_pids\"].astype(\"int64\")\n",
    "test_sim_rec_df = test_sim_rec_df.drop_duplicates([\"uid\", \"aid\", \"sim_pids\"])\n",
    "\n",
    "test_ui_reldata = {}\n",
    "test_ai_reldata = {}\n",
    "for i, row in tqdm(test_sim_rec_df.iterrows(), total=len(test_sim_rec_df)):\n",
    "    uid, aid, simpid = row.uid, row.aid, row.sim_pids\n",
    "    if uid not in test_ui_reldata:\n",
    "        test_ui_reldata[uid] = {}\n",
    "        test_ui_reldata[uid][simpid] = 1.\n",
    "    else:\n",
    "        test_ui_reldata[uid][simpid] = 1.\n",
    "    if aid not in test_ai_reldata:\n",
    "        test_ai_reldata[aid] = {}\n",
    "        test_ai_reldata[aid][simpid] = 1.\n",
    "    else:\n",
    "        test_ai_reldata[aid][simpid] = 1.\n",
    "            \n",
    "test_uids = np.array(test_sim_rec_df.uid.unique())\n",
    "test_aids = np.array(test_sim_rec_df.aid.unique())\n",
    "\n",
    "def get_ranking(model, uids, batch_size=2048, topk=1000):\n",
    "    uid_to_ranklist = {}\n",
    "    start_idx = 0\n",
    "    while start_idx < len(uids):\n",
    "        end_idx = min(len(uids), start_idx+batch_size)\n",
    "        batch_uids = uids[start_idx: end_idx]\n",
    "        score = -model.user_factors[batch_uids] @ model.item_factors.T # [bz, num_items]\n",
    "        top_indices = np.argpartition(score, topk, axis=-1)\n",
    "        batch_top_pids = top_indices[:, :topk]\n",
    "        #top_pids = top_indices[score[top_indices].argsort()]\n",
    "        \n",
    "        for i, (uid, top_pids) in enumerate(zip(batch_uids, batch_top_pids)):\n",
    "            assert len(top_pids) == topk\n",
    "            uid_to_ranklist[uid] = top_pids[score[i][top_pids].argsort()]\n",
    "        \n",
    "        start_idx = end_idx\n",
    "        print(start_idx, start_idx / len(uids))\n",
    "            \n",
    "    return uid_to_ranklist\n",
    "\n",
    "uid_to_ranklist = get_ranking(ui_model, test_uids)\n",
    "aid_to_ranklist = get_ranking(ai_model, test_aids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "84523ac9-8235-4fde-bbfb-faa20aed01a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "def _calculate_metrics_plain(ranking, qrels,binarization_point=1.0,return_per_query=False):\n",
    "    '''\n",
    "    calculate main evaluation metrics for the given results (without looking at candidates),\n",
    "    returns a dict of metrics\n",
    "    '''\n",
    "\n",
    "    ranked_queries = len(ranking)\n",
    "\n",
    "    qidx_to_qid = {idx:qid for idx, qid in enumerate(ranking)}\n",
    "\n",
    "    rr_per_candidate_depth = np.zeros((2,ranked_queries))\n",
    "    rank_per_candidate_depth = np.zeros((2,ranked_queries))\n",
    "    recall_per_candidate_depth = np.zeros((2,ranked_queries))\n",
    "    ndcg_per_candidate_depth = np.zeros((2,ranked_queries))\n",
    "    ap_per_candidate_depth = np.zeros((ranked_queries))\n",
    "    evaluated_queries = 0\n",
    "\n",
    "    for query_index,(query_id,ranked_doc_ids) in enumerate(ranking.items()):\n",
    "        if query_id in qrels:\n",
    "            evaluated_queries += 1\n",
    "\n",
    "            relevant_ids = np.array(list(qrels[query_id].keys())) # key, value guaranteed in same order\n",
    "            relevant_grades = np.array(list(qrels[query_id].values()))\n",
    "            sorted_relevant_grades = np.sort(relevant_grades)[::-1]\n",
    "\n",
    "            num_relevant = relevant_ids.shape[0]\n",
    "            np_rank = np.array(ranked_doc_ids)\n",
    "            relevant_mask = np.in1d(np_rank,relevant_ids) # shape: (ranking_depth,) - type: bool\n",
    "\n",
    "            binary_relevant = relevant_ids[relevant_grades >= binarization_point]\n",
    "            binary_num_relevant = binary_relevant.shape[0]\n",
    "            binary_relevant_mask = np.in1d(np_rank,binary_relevant) # shape: (ranking_depth,) - type: bool\n",
    "\n",
    "            # check if we have a relevant document at all in the results -> if not skip and leave 0 \n",
    "            if np.any(binary_relevant_mask):\n",
    "\n",
    "                # now select the relevant ranks across the fixed ranks\n",
    "                ranks = np.arange(1,binary_relevant_mask.shape[0]+1)[binary_relevant_mask]\n",
    "\n",
    "                #\n",
    "                # ap\n",
    "                #\n",
    "                map_ranks = ranks[ranks <= 1000]\n",
    "                ap = np.arange(1,map_ranks.shape[0]+1) / map_ranks\n",
    "                ap = np.sum(ap) / binary_num_relevant\n",
    "                ap_per_candidate_depth[query_index] = ap\n",
    "\n",
    "                # mrr only the first relevant rank is used\n",
    "                first_rank = ranks[0]\n",
    "\n",
    "                for cut_indx, cutoff in enumerate([10, 1000]):\n",
    "\n",
    "                    curr_ranks = ranks.copy()\n",
    "                    curr_ranks[curr_ranks > cutoff] = 0 \n",
    "                    #\n",
    "                    # mrr\n",
    "                    #\n",
    "\n",
    "                    # ignore ranks that are out of the interest area (leave 0)\n",
    "                    if first_rank <= cutoff: \n",
    "                        rr_per_candidate_depth[cut_indx,query_index] = 1 / first_rank\n",
    "                        rank_per_candidate_depth[cut_indx,query_index] = first_rank\n",
    "\n",
    "                for cut_idx, cutoff in enumerate([10,1000]):\n",
    "                    curr_ranks = ranks.copy()\n",
    "                    curr_ranks[curr_ranks > cutoff] = 0 \n",
    "                    recall = (curr_ranks > 0).sum(axis=0) / binary_num_relevant\n",
    "                    recall_per_candidate_depth[cut_idx,query_index] = recall\n",
    "\n",
    "            if np.any(relevant_mask):\n",
    "\n",
    "                # now select the relevant ranks across the fixed ranks\n",
    "                ranks = np.arange(1,relevant_mask.shape[0]+1)[relevant_mask]\n",
    "\n",
    "                grades_per_rank = np.ndarray(ranks.shape[0],dtype=int)\n",
    "                for i,id in enumerate(np_rank[relevant_mask]):\n",
    "                    grades_per_rank[i]=np.where(relevant_ids==id)[0]\n",
    "\n",
    "                grades_per_rank = relevant_grades[grades_per_rank]\n",
    "\n",
    "                #\n",
    "                # ndcg = dcg / idcg \n",
    "                #\n",
    "                for cut_indx, cutoff in enumerate([10,1000]):\n",
    "                    #\n",
    "                    # get idcg (from relevant_ids)\n",
    "                    idcg = (sorted_relevant_grades[:cutoff] / np.log2(1 + np.arange(1,min(num_relevant,cutoff) + 1)))\n",
    "\n",
    "                    curr_ranks = ranks.copy()\n",
    "                    curr_ranks[curr_ranks > cutoff] = 0 \n",
    "\n",
    "                    #coverage_per_candidate_depth[cut_indx, query_index] = (curr_ranks > 0).sum() / float(cutoff)\n",
    "\n",
    "                    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                        c = np.true_divide(grades_per_rank,np.log2(1 + curr_ranks))\n",
    "                        c[c == np.inf] = 0\n",
    "                        dcg = np.nan_to_num(c)\n",
    "\n",
    "                    nDCG = dcg.sum(axis=-1) / idcg.sum()\n",
    "\n",
    "                    ndcg_per_candidate_depth[cut_indx,query_index] = nDCG\n",
    "\n",
    "    #avg_coverage = coverage_per_candidate_depth.sum(axis=-1) / evaluated_queries\n",
    "    mrr = rr_per_candidate_depth.sum(axis=-1) / evaluated_queries\n",
    "    relevant = (rr_per_candidate_depth > 0).sum(axis=-1)\n",
    "    non_relevant = (rr_per_candidate_depth == 0).sum(axis=-1)\n",
    "\n",
    "    \"\"\"\n",
    "    avg_rank=np.apply_along_axis(lambda v: np.mean(v[np.nonzero(v)]), -1, rank_per_candidate_depth)\n",
    "    avg_rank[np.isnan(avg_rank)]=0.\n",
    "\n",
    "    median_rank=np.apply_along_axis(lambda v: np.median(v[np.nonzero(v)]), -1, rank_per_candidate_depth)\n",
    "    median_rank[np.isnan(median_rank)]=0.\n",
    "    \"\"\"\n",
    "    map_score = ap_per_candidate_depth.sum(axis=-1) / evaluated_queries\n",
    "    recall = recall_per_candidate_depth.sum(axis=-1) / evaluated_queries\n",
    "    nDCG = ndcg_per_candidate_depth.sum(axis=-1) / evaluated_queries\n",
    "\n",
    "    local_dict={}\n",
    "\n",
    "    for cut_indx, cutoff in enumerate([10,1000]):\n",
    "\n",
    "        local_dict['MRR@'+str(cutoff)] = mrr[cut_indx]\n",
    "        #local_dict['QueriesWithNoRelevant@'+str(cutoff)] = non_relevant[cut_indx]\n",
    "        local_dict['QueriesWithRelevant@'+str(cutoff)] = relevant[cut_indx]\n",
    "        #local_dict['AverageRankGoldLabel@'+str(cutoff)] = avg_rank[cut_indx]\n",
    "        #local_dict['MedianRankGoldLabel@'+str(cutoff)] = median_rank[cut_indx]\n",
    "\n",
    "    for cut_indx, cutoff in enumerate([10,1000]):\n",
    "        local_dict['Recall@'+str(cutoff)] = recall[cut_indx]\n",
    "\n",
    "    for cut_indx, cutoff in enumerate([10,1000]):\n",
    "        #local_dict['Avg_coverage@'+str(cutoff)] = avg_coverage[cut_indx]\n",
    "        local_dict['nDCG@'+str(cutoff)] = nDCG[cut_indx]\n",
    "\n",
    "    local_dict[\"MAP@\"+str(1000)] = map_score\n",
    "\n",
    "    local_dict['QueriesRanked'] = evaluated_queries\n",
    "\n",
    "    if return_per_query:\n",
    "        return local_dict,rr_per_candidate_depth,recall_per_candidate_depth,ndcg_per_candidate_depth, qidx_to_qid, qrels\n",
    "    else:\n",
    "        return local_dict\n",
    "        \n",
    "ui_result = _calculate_metrics_plain(uid_to_ranklist, test_ui_reldata)\n",
    "ai_result = _calculate_metrics_plain(aid_to_ranklist, test_ai_reldata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bdfde62-82a1-4431-983a-3cac47a28c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'MRR@10': 0.12848136732161516,\n",
       "  'QueriesWithRelevant@10': 19666,\n",
       "  'MRR@1000': 0.13421565944717023,\n",
       "  'QueriesWithRelevant@1000': 43670,\n",
       "  'Recall@10': 0.2148971226235994,\n",
       "  'Recall@1000': 0.5136589299708912,\n",
       "  'nDCG@10': 0.14111959727735726,\n",
       "  'nDCG@1000': 0.19248874069304256,\n",
       "  'MAP@1000': 0.11840409862342591,\n",
       "  'QueriesRanked': 81664},\n",
       " {'MRR@10': 0.1465949792494564,\n",
       "  'QueriesWithRelevant@10': 9988,\n",
       "  'MRR@1000': 0.15065814610725997,\n",
       "  'QueriesWithRelevant@1000': 15242,\n",
       "  'Recall@10': 0.170981202532537,\n",
       "  'Recall@1000': 0.35062336823934886,\n",
       "  'nDCG@10': 0.12993301089907136,\n",
       "  'nDCG@1000': 0.17442168253031834,\n",
       "  'MAP@1000': 0.10880731329619221,\n",
       "  'QueriesRanked': 40718})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ui_result, ai_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4314cf-5114-4d96-a76e-dc57e5540c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-9.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-9:m93"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
